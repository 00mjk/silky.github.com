<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>silky.github.io</title>
    <link href="https://silky.github.io/atom.xml" rel="self" />
    <link href="https://silky.github.io" />
    <id>https://silky.github.io/atom.xml</id>
    <author>
        <name>Noon van der Silk</name>
        <email>noonsilk+-noonsilk@gmail.com</email>
    </author>
    <updated>2017-01-07T00:00:00Z</updated>
    <entry>
    <title>Forging quantum money (part 2 of 3)</title>
    <link href="https://silky.github.io/posts/2017-01-07-forging-quantum-money-part-2.html" />
    <id>https://silky.github.io/posts/2017-01-07-forging-quantum-money-part-2.html</id>
    <published>2017-01-07T00:00:00Z</published>
    <updated>2017-01-07T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on January  7, 2017
    
        by Noon van der Silk
    
</div>

<p>This post is the second of a three-part series on the paper <a href="https://arxiv.org/abs/1404.1507">An adaptive attack on Wiesner’s quantum money</a>.</p>
<ol style="list-style-type: decimal">
<li><a href="/post/2017-01-06-forging-quantum-money-part-1.html">Wiesner’s scheme for quantum money, and why it was considered secure</a>,</li>
<li><a href="#">An attack on Wiesner’s money scheme that shows it is not secure (with an aside into quantum bomb testing!)</a> (this post),</li>
<li>and, A modification of Wiesner’s scheme that resists this attack.</li>
</ol>
<p>Now that we are familiar with Wiesner’s money, we can</p>
<h1 id="the-attack-by-brodutch-nagaj-sattath-and-unruh-bnsu">The attack by Brodutch, Nagaj, Sattath and Unruh (BNSU)</h1>
<p>BNSU actually introduce two attacks, one more general than the other, but I’ll focus on the less general one; the <em>bomb testing</em> attack, because it’s more fun.</p>
<p>Let’s first take a brief aside into bomb-testing.</p>
<h2 id="bomb-testing">Bomb testing</h2>
<p>Suppose I give you 10 bombs. <!--
    http://codepen.io/Xanmia/pen/DoljI
    --></p>
]]></summary>
</entry>
<entry>
    <title>Forging quantum money (part 1 of 3)</title>
    <link href="https://silky.github.io/posts/2017-01-06-forging-quantum-money-part-1.html" />
    <id>https://silky.github.io/posts/2017-01-06-forging-quantum-money-part-1.html</id>
    <published>2017-01-06T00:00:00Z</published>
    <updated>2017-01-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on January  6, 2017
    
        by Noon van der Silk
    
</div>

<p>Due to the release of (yet another) Python framework for quantum simulation <a href="https://github.com/silky/ProjectQ">ProjectQ</a>, I was inspired to revisit the paper <a href="https://arxiv.org/abs/1404.1507">An adaptive attack on Wiesner’s quantum money</a> from a few years back.</p>
<p>This post will form the first post of a three-part series on the paper, and the background necessary to understand the part of it I’ll cover. We’ll learn about:</p>
<ol style="list-style-type: decimal">
<li><a href="#">Wiesner’s scheme for quantum money, and why it was considered secure</a> (this post),</li>
<li>An attack on Wiesner’s money scheme that shows it is not secure (with an aside into quantum bomb testing!),</li>
<li>and, A modification of Wiesner’s scheme that resists this attack.</li>
</ol>
<h1 id="wiesners-scheme">Wiesner’s scheme</h1>
<p>Wiesner’s Quantum Money scheme is one of the earliest ideas in quantum computing. The fundamental idea is that (unknown) quantum states <a href="https://en.wikipedia.org/wiki/No-cloning_theorem">cannot be copied arbitrariy</a> and hence make an “unforgable” form of money: it shouldn’t be possible to duplicate a “quantum” bill.</p>
<p>Money, in Wiesner’s scheme, is created by the bank. The bank holds a serial number and a secret “key” that the bank uses to verify each note that it hands out. When given a note, the bank can determine if it is valid by referring back to this secret key.</p>
<p>The important steps are:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Money generation</strong>: Done by the bank here; the bank creates money by randomly picking a quantum state, called it <span class="math inline">\(|\$\rangle\)</span>, and handing that state to the customer, and recording the state it generated by matching it to the serial number of the note.</p></li>
<li><p><strong>Money verification</strong>: When someone wishes to spend money, the bank verifies it.</p></li>
</ol>
<p>Let’s take a look in detail. We’ll first need to recall some standard quantum states:</p>
<p><span class="math display">\[ \begin{aligned}
    |0\rangle &amp;= \left( \begin{array}{c}
        1 \\ 0
    \end{array} \right), \\
    |1\rangle &amp;= \left( \begin{array}{c}
        0 \\ 1
    \end{array} \right), \\
    |+\rangle &amp;= \frac{1}{\sqrt{2}} \left( |0\rangle + |1\rangle \right), \\
    |-\rangle &amp;= \frac{1}{\sqrt{2}} \left( |0\rangle - |1\rangle \right).
\end{aligned} \]</span></p>
<p>The first two states, <span class="math inline">\(\{|0\rangle, |1\rangle\}\)</span> form a <em>basis</em><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> – the <em>computational</em> basis – for a single qubit, and the second two, <span class="math inline">\(\{|+\rangle, |-\rangle\}\)</span> form a different, orthogonal, basis – the <em>Hadamard</em> basis.</p>
<p>The crucial idea to understanding the scheme is that in quantum mechanics, <em>measurement</em> can irreversibly destroy a given quantum state, changing it to be a completely different one.</p>
<h2 id="measurement">Measurement</h2>
<p>To <em>measure</em> a given state in quantum mechanics is to first fix a set of potential measurement outcomes, and then “look” at the given state, and see which one of these outcomes the state when in. Let’s see an example.</p>
<p>Suppose we have a single qubit in some unknown state:</p>
<p><span class="math display">\[ \begin{aligned}
    |\psi\rangle &amp;= \alpha |0\rangle + \beta |1\rangle
\end{aligned} \]</span></p>
<p>We can <em>measure</em> the qubit in either the <em>computational</em> basis or the <em>Hadamard</em> basis.</p>
<p><strong>Computational basis</strong>. Noting that it is already express in <em>terms</em> of the computationl basis, if we measure it in the computational basis, the <a href="https://en.wikipedia.org/wiki/Born_rule">Born rule</a> for measurement says that we will get the state <span class="math inline">\(|0\rangle\)</span> with probabily <span class="math inline">\(|\alpha|^2\)</span> and the state <span class="math inline">\(|1\rangle\)</span> with probabily <span class="math inline">\(|\beta|^2\)</span>.</p>
<p><strong>Hadamard basis</strong>: Note that <span class="math inline">\(|0\rangle = \frac{1}{\sqrt{2}} \left( |+\rangle + |-\rangle \right)\)</span> and <span class="math inline">\(|1\rangle = \frac{1}{\sqrt{2}} \left(|+\rangle - |-\rangle \right)\)</span> so we can re-write <span class="math inline">\(|\psi\rangle\)</span> as <span class="math display">\[ \begin{aligned}
    |\psi\rangle &amp;= \frac{\alpha + \beta}{\sqrt{2}} |+\rangle + 
                    \frac{\alpha - \beta}{\sqrt{2}} |-\rangle
\end{aligned} \]</span> and so, again by the Born rule, we would achieve outcome <span class="math inline">\(|+\rangle\)</span> with probability <span class="math inline">\(\left|\frac{\alpha + \beta}{\sqrt{2}}\right|^2\)</span> and <span class="math inline">\(|-\rangle\)</span> with probability <span class="math inline">\(\left|\frac{\alpha - \beta}{\sqrt{2}}\right|^2\)</span>.</p>
<p>The point to note here is that the final state is <em>different</em> depending on which basis we measured it in. Wiesner used this fact to build a (hopefully) unforgable form of money.</p>
<h2 id="wiesners-quantum-money">Wiesner’s quantum money</h2>
<p><strong>Money generation</strong>: To withdraw money from a bank in Wiesner’s scheme, the bank performs the following steps:</p>
<ol style="list-style-type: decimal">
<li>Pick a serial number, <span class="math inline">\(s\)</span>,</li>
<li>Pick <span class="math inline">\(n\)</span> states at random from <span class="math inline">\(|0\rangle, |1\rangle, |+\rangle,  |-\rangle\)</span>, call this the <em>key</em> and save these choices in a database linked to the serial number.</li>
<li>Build a quantum state from these basis elements, and call the combined state <span class="math inline">\(|\$\rangle\)</span>.</li>
<li>Yield a bank note to the customer with the given serial number <span class="math inline">\(s\)</span> and the embedded quantum state <span class="math inline">\(|\$\rangle\)</span>.</li>
</ol>
<center>
<img src="../images/quantum-money-withdrawal.png" width="100%" />
</center>
<p><strong>Money verification</strong>: To verify a given piece of money, the bank proceeds as follows:</p>
<ol style="list-style-type: decimal">
<li>Look up the key for the provided serial number <span class="math inline">\(s\)</span>,</li>
<li>Measure each qubit in the basis that the we know it was created from.</li>
<li>If the money state hasn’t changed, then we will measure it to be in the same state that we created it, and we can say that it is valid.
<center>
<img src="../images/quantum-money-spend-valid.png" width="100%" />
</center></li>
<li>If the money state <em>has</em> changed, then there is a chance that the measurement results will disagree, and we can be sure that it has been tampered with.
<center>
<img src="../images/quantum-money-spend-invalid.png" width="100%" />
</center></li>
<li>In the case that validation succeeds, the money state is returned to the person requesting validation, and in the case that the validation fails, the money is destroyed.</li>
</ol>
<p>Having the <em>same</em> money state returned, instead of a new one each time validation succeeds, is critical to the success of the forging approach of <a href="https://arxiv.org/pdf/1404.1507v4.pdf">arXiv:1404.1507</a>.</p>
<h2 id="standard-analysis-of-wiesners-scheme">Standard analysis of Wiesner’s scheme</h2>
<p>Let’s look at an example. Suppose we have withdrawn some money from the bank, and the state we’ve been given (but can’t see) is</p>
<p><span class="math display">\[ \begin{aligned}
    |\$\rangle &amp;= |+100--\rangle.
\end{aligned} \]</span></p>
<p>There are six qubits, and <em>we</em> can see the bases that each has been prepared in, but if we’re simply the customer we don’t know this information.</p>
<p>Our goal is to create a state <span class="math inline">\(|F\rangle\)</span> that the bank will <em>also</em> verify as valid.</p>
<p>Noting that if we measure either <span class="math inline">\(|+\rangle\)</span> or <span class="math inline">\(|-\rangle\)</span> in the computational basis, we’ll get <span class="math inline">\(|0\rangle\)</span> with 50% probability or <span class="math inline">\(|1\rangle\)</span> with 50% probability, one approach is simply to build <span class="math inline">\(|F\rangle\)</span> by the following technique:</p>
<ol style="list-style-type: decimal">
<li>Measure each qubit indepnedently in the <em>computational basis</em>, and obtain some measurement outcome <span class="math inline">\(x \in \{0, 1\}\)</span>.</li>
<li>In this way, build up <span class="math inline">\(|F\rangle\)</span> from states <span class="math inline">\(|x\rangle\)</span>.</li>
</ol>
<p>In our example, we can see that this will work 50% of the time for the first qubit of <span class="math inline">\(|\$\rangle\)</span>, 100% of the time for the 2nd, 3rd and 4th qubits, and again 50% of the time for the last two qubits. So for this state, this approach will succeed with probability <span class="math inline">\(\left( \frac{1}{2} \right)^3 = \frac{1}{8}\)</span>. Pretty bad odds.</p>
<p>In an earlier paper, <a href="https://arxiv.org/pdf/1202.4010.pdf">Molina Vidick and Watrous</a> show that in a model where the attacker <em>doesn’t</em> interact with the bank after receiving the note, the best attack that one can mount results in a success probability of <span class="math inline">\(\left(\frac{3}{4}\right)^n\)</span>, where <span class="math inline">\(n\)</span> is the number of qubits in the money state. This is better than my approach here, but if we set <span class="math inline">\(n\)</span> to be of modest size, say <span class="math inline">\(n = 10\)</span>, then this approach will succeed <em>at most</em> 5 times out of 100; still not particularly good. If we had 100 twenty dollar notes, we could attempt to forge them, and we’d end up with a total of <span class="math inline">\(2 \times 5 \times 20 = \$200\)</span> instead of the original <span class="math inline">\(\$2,000\)</span> we started with.</p>
<h1 id="summary">Summary</h1>
<p>We’ve seen that Wiesner’s original scheme for quantum money doesn’t appear to be forgable with our first ideas. In the next post we’ll learn about a very cool technique in quantum mechanics, the <a href="https://en.wikipedia.org/wiki/Elitzur%E2%80%93Vaidman_bomb_tester">Elitzur-Vaidman bomb tester</a>, and then we’ll see how it can be used to beat Wiesner’s scheme!</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>A one-qubit <em>basis</em> is a set of states such that any state involving one qubit can be written as a linear combination of either of the elements in the basis.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
]]></summary>
</entry>
<entry>
    <title>Quantum neural networks</title>
    <link href="https://silky.github.io/posts/2016-12-11-quantum-neural-networks.html" />
    <id>https://silky.github.io/posts/2016-12-11-quantum-neural-networks.html</id>
    <published>2016-12-11T00:00:00Z</published>
    <updated>2016-12-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on December 11, 2016
    
        by Noon van der Silk
    
</div>

<p>(This post requires a background in the basics of quantum computing (and neural networks). Please have a read of the first part of <a href="/posts/2014-09-09-intro-to-qc-and-the-surface-code.html">Introduction to quantum computing and the surface code</a> if you’d like to get up to speed on the quantum parts, <a href="http://neuralnetworksanddeeplearning.com/">Neural networks and Deep Learning</a> is a good introduction to the other part.)</p>
<p>Recently, I’ve been spending a lot of time thinking about machine learning, and in particular deep learning. But before that, I was mostly concerning myself with quantum computing, and specifically the algorithmic/theory side of quantum computing.</p>
<p>In the last few days there’s been a flurry of papers on quantum machine learning/quantum neural networks, and related topics. Infact, there’s been a fair bit of research in the last few years (see the <a href="#appendix">Appendix</a> at the end for a few links), and I thought I’d take this opportunity to have a look at what people are up to.</p>
<p>The papers we’ll be discussing are:</p>
<ul>
<li><a href="https://scirate.com/arxiv/1612.01045">arXiv:1612.01045 - Quantum generalisation of feedforward neural networks</a> by Wan, Dahlsten, Kristjánsson, Gardner and Kim.</li>
<li><a href="https://scirate.com/arxiv/1612.01789">arXiv:1612.01789 - Quantum gradient descent and Newton’s method for constrained polynomial optimization</a> by Rebentrost, Schuld, Petruccione and Lloyd,</li>
<li><a href="https://scirate.com/arxiv/1612.02806">arXiv:1612.02806 - Quantum autoencoders for efficient compression of quantum data</a> by Romero, Olson and Aspuru-Guzik,</li>
</ul>
<p>But first, let’s take a look at the paper that got me interested in machine learning in the first place!</p>
<h2 id="arxiv1307.0411---quantum-algorithms-for-supervised-and-unsupervised-machine-learning">arXiv:1307.0411 - Quantum algorithms for supervised and unsupervised machine learning</h2>
<p>The paper, <a href="https://scirate.com/arxiv/1307.0411">Quantum algorithms for supervised and unsupervised machine learning</a> by Lloyd, Mohseni and Rebentrost in 2013, was one of my first technical exposures to machine learning. It’s an interesting one because it demonstrates that for certain types of clustering algorithms there is a quantum algorithm that exhibits an exponential speed-up over the classical counterpart.</p>
<p><strong>Aside</strong>: Gaining complexity-theoretic speed-ups is the central task of (quantum) complexity theory. The speedup in this paper is interested, but it “only” demonstrates a speed-up on a problem that is already known to be <em>efficient</em><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> for classical computers, so it <em>doesn’t</em> provide evidence that quantum computers are fundamentally more powerful than classical ones, by the standard notions in computer science.</p>
<p>The <code>Supervised clustering</code> problem that is tackled in the paper is as follows:</p>
<blockquote>
<p>Given some vector <span class="math inline">\(\vec{u} \in \mathbb{R}^N\)</span>, and two sets of vectors <span class="math inline">\(V\)</span> and <span class="math inline">\(W\)</span>, then given <span class="math inline">\(M\)</span> representative samples from <span class="math inline">\(V\)</span>: <span class="math inline">\(\vec{v}_j \in V\)</span> and <span class="math inline">\(\vec{w}_k \in W\)</span>, figure out which set <span class="math inline">\(\vec{u}\)</span> should go in to, by comparing the distances to these vectors.</p>
</blockquote>
<p>In pictures it looks like so:</p>
<div style="text-align: center">
<div class="figure">
<img src="../images/supervised-clustering.png" alt="Figure 1. An example of the supervised clustering problem with \vec{u} \in \mathbb{R}^2 and M=3. We’ve drawn 3 points from V, the (unknown) dashed purple region, and 3 points from W, the dashed pink region." />
<p class="caption">Figure 1. An example of the supervised clustering problem with <span class="math inline">\(\vec{u} \in \mathbb{R}^2\)</span> and <span class="math inline">\(M=3\)</span>. We’ve drawn 3 points from <span class="math inline">\(V\)</span>, the (unknown) dashed purple region, and 3 points from <span class="math inline">\(W\)</span>, the dashed pink region.</p>
</div>
</div>
<p>Classically, if we think about where we’d like to put <span class="math inline">\(\vec{u}\)</span>, we could compare the distance to all the points <span class="math inline">\(\vec{v_1}, \vec{v_2}, \vec{v_3}\)</span> and to all the points <span class="math inline">\(\vec{w_1}, \vec{w_2},\vec{w_3}\)</span>. In the specific example I’ve drawn, doing so will show that, out of the two sets, <span class="math inline">\(\vec{u}\)</span> belongs in <span class="math inline">\(V\)</span>.</p>
<p>In general, we can see that, using this approach, we would need to look at all <span class="math inline">\(M\)</span> data points, and we’d need to compare each dimension of the <span class="math inline">\(N\)</span> dimensions of each vector <span class="math inline">\(\vec{v_j}, \vec{w_k}, \vec{u}\)</span>; i.e. we’d need to look at at least <span class="math inline">\(M\times N\)</span> pieces of information. In other words, we’d compute the distance</p>
\begin{align*}
    d(\vec{u}, V) = \left| \vec{u} - \frac{1}{M}\sum_{j=1}^{M} \vec{v_j} \right|
\end{align*}
<p>By looking at the problem slightly more formally, we find that classically the best known algorithm takes “something like”<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <span class="math inline">\(\texttt{pol}y(M\times N)\)</span> steps, where “<span class="math inline">\(\texttt{poly}\)</span>” means that the true running time is a polynomial of <span class="math inline">\(M\times N\)</span>.</p>
<p>Quantumly, the paper demonstrates an algorithm that lets us solve this problem in “something like” <span class="math inline">\(\log(M\times N)\)</span> time steps. This is a significant improvement, in a practical sense. To get an idea, if we took <span class="math inline">\(100\)</span> samples from a <span class="math inline">\(N = 350\)</span>-dimensional space, then <span class="math inline">\(M\times N = 35,000\)</span> and <span class="math inline">\(\log(M \times N) \approx 10\)</span>.</p>
<p>The quantum algorithm works by constructing a state in a certain state so that, when measured, the distance that we wanted, <span class="math inline">\(d(\vec{u}, V)\)</span>, is the probability that we achieve a certain measurement outcome. In this way, we can build this certain state, and measure it, several times, and use this information to approximate the required distances. And, the paper shows that this whole process can be done in “something like” a running time of <span class="math inline">\(\log(M\times N)\)</span>.</p>
<p>There’s more contirbutions in the paper than just this; so it’s worth a look if you’re interested.</p>
<h2 id="arxiv16.12.01045---quantum-generalisation-of-feedforward-neural-networks">arXiv:16.12.01045 - Quantum generalisation of feedforward neural networks</h2>
<p>So this paper is pretty cool. We can get a feel for what it’s doing by first considering the following network:</p>
<div style="text-align: center">
<div class="figure">
<img src="../images/basic-nn.png" alt="Figure 2. A simple classical neural network" />
<p class="caption">Figure 2. A simple classical neural network</p>
</div>
</div>
<p>This network has two inputs, <span class="math inline">\(x_1, x_2\)</span>, three learnable weights, <span class="math inline">\(w_1, w_2, w_3\)</span>, one output value <span class="math inline">\(y\)</span>, and an activation function <span class="math inline">\(f\)</span>.</p>
<p>Classically one would feed in a series of training examples <span class="math inline">\((x_1, x_2, y)\)</span> and update the weights according to some loss function to achieve the best result for the given data.</p>
<p>Quantumly, there are some immediate problems with doing this, if we switch the inputs <span class="math inline">\(x\)</span> to be quantum states, instead of classical real variables.</p>
<p>The problems are:</p>
<ul>
<li>Quantum operations need to be reversible; <span class="math inline">\(f\)</span> as written is not (at the very least, it takes two inputs and squashes them down to one output).</li>
<li>Quantum states need to be normalised; so multiplying them by a single arbitrary weight won’t be productive.</li>
<li>You can’t copy arbitrary quantum states due to the <a href="https://en.wikipedia.org/wiki/No-cloning_theorem">No-Cloning theorem</a>, so this restricts the type of networks that can be written down.</li>
</ul>
<p>The way this paper solves these problems is to transition Figure 2 from a classical non-reversible network to a reversible quantum one:</p>
<div style="text-align: center">
<div class="figure">
<img src="../images/transition-to-quantum-nn.png" alt="Figure 3. The transition from classical, to reversible classical, to quantum." />
<p class="caption">Figure 3. The transition from classical, to reversible classical, to quantum.</p>
</div>
</div>
<p>The final network takes in an arbitrary quantum state of two qubits, <span class="math inline">\(x_1, x_2\)</span>, and then adjoins an ancilla state <span class="math inline">\(|0\rangle\)</span>, applies some unitary operation <span class="math inline">\(U\)</span>, and emits a combined final state <span class="math inline">\(|\psi\rangle^{\text{Out}}_{x_1,x_2,y}\)</span> where the final qubit <span class="math inline">\(y\)</span> contains the result we’re interested in.</p>
<p>At this point, one might reasonably ask: How is this different to a quantum circuit? It appears to me that the only difference is that <span class="math inline">\(U\)</span> is actually unknown, and <em>it</em> is trainable! Note that this is also a somewhat radical difference from classical neural networks: there, we don’t normally think of the activation functions (defined as <span class="math inline">\(f\)</span> above) as trainable parameters; but quantumly, in this paper, that’s exactly how we think of them!</p>
<p>It turns out that unitary matrices can be parameterised by a collection of real variables <span class="math inline">\(\alpha\)</span>. Consider an arbitrary unitary matrix operating on two qubits, then <span class="math inline">\(U\)</span> can be written as:</p>
\begin{align*}
    U = \exp\left[ i \left(
             \sum_{j_1,j_2=0,0}^{3,3} \alpha_{j_1, j_2} \times \left(\sigma_{j_1}
             \otimes \sigma_{j_2}\right) \right) \right]
\end{align*}
<p>where <span class="math inline">\(\sigma_i, i \in {1,2,3}\)</span> are the usual <a href="https://en.wikipedia.org/wiki/Pauli_matrices">Pauli matrices</a> and <span class="math inline">\(\sigma_0\)</span> is the <span class="math inline">\(2\times 2\)</span> identity matrix. So one can then make these parameters <span class="math inline">\(\alpha_{j_1, j_2}\)</span> the <em>trainable</em> parameters! <s>It turns out that in the paper they don’t train these parameters explicitly, instead they pick a less general way of writing down unitary matricies, and they construct, by hand, a unitary for two qubits. It’s not clear why they’ve done this, and it would not be fun to have to build a special trainable unitary matrix for each node/neuron of your architecture depending on its input.</s></p>
<p><strong>Update:</strong> Kwok-Ho kindly corrected me that they <em>do</em> indeed train directly on this form of unitary matricies, and that the simplification they do in the paper is used to investigate the loss surface.</p>
<p>In any case, the main contribution of this paper seems to me to be the idea that we can <em>learn</em> unitary matricies for our particular problem. They go on to demonstrate that this idea works to build a quantum autoencoder, and to make a neural network discover unitary matricies that perform the quantum teleportation protocol.</p>
<p>One view is that trying to learn arbitrary unitary matrices that perform a task really well will become too hard as the number neurons grows. If we had a large network, with potentially millions of internal, neurons (and hence unitaries) to learn, then it might be more effective to fix unitaries and instead focus on learning the weights.</p>
<p>However, it’s a promising technique that would be fun to try out.</p>
<h2 id="arxiv1612.01789---quantum-gradient-descent-and-newtons-method-for-constrained-polynomial-optimization">arXiv:1612.01789 - Quantum gradient descent and Newton’s method for constrained polynomial optimization</h2>
<p>Those of you familiar with neural networks will know that the central idea used to train them is <a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient Descent</a>. We recall that gradient descent lets us known how to modify some vector <span class="math inline">\(x\)</span> so that it does “better” when evaluated with some cost function <span class="math inline">\(C(x, y)\)</span> where <span class="math inline">\(y\)</span> is some known good answer. I.e. <span class="math inline">\(x\)</span> might be a probability of liking some object, and <span class="math inline">\(y\)</span> might be the true probability, and <span class="math inline">\(C(x,y) = |x-y|^2\)</span>.</p>
<p>The paper supposes we have some quantum state <span class="math inline">\(|x\rangle = \sum_{j=1}^N x_j |j\rangle\)</span> (where <span class="math inline">\(|j\rangle\)</span> is the <span class="math inline">\(j\)</span>’th computational-basis state), and some cost function <span class="math inline">\(C(|x\rangle, |y\rangle)\)</span> that tells us how good <span class="math inline">\(|x\rangle\)</span> is. The question is, given we can evaluate <span class="math inline">\(C(|x\rangle, |y\rangle)\)</span>, how can we best work out to modify <span class="math inline">\(|x\rangle\)</span> to do better?</p>
<p>If this was entirely classical, we could just calculate the gradient of <span class="math inline">\(C\)</span> with respect to the variables <span class="math inline">\(x_j\)</span>, and then propose a new set of <span class="math inline">\(x_j\)</span>’s. However, we can’t inspect all these values quantumly, so we need to do something else.</p>
<p>In the paper, they demonstrate an approach that requires a few copies of the current state <span class="math inline">\(|x^{(t)}\rangle\)</span>, but will produce a new state <span class="math inline">\(|x^{(t+1)}\rangle\)</span> such that (with objective/loss function <span class="math inline">\(f\)</span>):</p>
\begin{align*}
    |x^{(t+1)}\rangle = |x^{(t)}\rangle - \eta |\nabla
    f\left(x^{(t)}\right)\rangle
\end{align*}
<p>for some step size <span class="math inline">\(\eta\)</span>. That is, it’s a step in the (hopefully) right direction, as per normal gradient descent!</p>
<p>So one direction to take this paper would be to build a “fully quantum” neural network like so:</p>
<div style="text-align: center">
<div class="figure">
<img src="../images/fully-quantum-nn.png" alt="Figure 5. Fully-quantum neural network. The inputs and the weights are quantum states; and the activation function U is unitary." />
<p class="caption">Figure 5. Fully-quantum neural network. The inputs and the weights are quantum states; and the activation function <span class="math inline">\(U\)</span> is unitary.</p>
</div>
</div>
<p>where we make the weights quantum states, and the weights are multiplied onto the inputs as a dot-product. This would require that the weight state is the same size as the input state; but that should be possible because we’re the ones building the network structure.</p>
<p>We could then not worry about learning unitary matrices, and analogously to standard neural networks, just pick some unitary <span class="math inline">\(U\)</span> that “works well” in practice, maybe by just defining quantum analogues of some common activation functions, perhaps say the <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU</a> or <a href="https://arxiv.org/abs/1511.07289">ELU</a>.</p>
<p>Overall I think that the quantum gradient descent algorithm should be useful for training neural networks, and maybe some cool things will come from it. There are some natural direct extensions of this work; namely to extend the implementation to <a href="http://sebastianruder.com/optimizing-gradient-descent/index.html">the more practical variations</a>.</p>
<h2 id="quantum-autoencoders-for-efficient-compression-of-quantum-data">1612.02806 - Quantum autoencoders for efficient compression of quantum data</h2>
<p>This paper came out only a few days after the Wan et al paper that we covered above, that also discussed autoencoders, so I thought it was worth a glance to see if this team did things differently.</p>
<p>This paper again takes the approach of not concerning itself with weights and instead focuses on learning a good unitary matrix <span class="math inline">\(U\)</span> with a specific cost function.</p>
<p>They take a different approach in how they build their unitaries. Here they have a “programmable” quantum circuit, where they consider the parameters defining this circuit as the ones that can be trained. Given that these parameters are classical, and loss function they calculate is classical, no special optimisation techniques are needed.</p>
<h2 id="final-thoughts">Final thoughts</h2>
<p>It appears that the building blocks are being put together to start doing some serious work on quantum machine learning/quantum deep networks. <a href="http://web.physics.ucsb.edu/~martinisgroup/">Google</a> and <a href="http://blogs.microsoft.com/next/2016/11/20/microsoft-doubles-quantum-computing-bet/#sm.001umo7pp17ozfkwvl81eu0szc8pf">Microsoft</a> are already heavily investing in quantum computers, Google in particular has something it calls the <a href="https://plus.google.com/+QuantumAILab">“Quantum A.I. Lab”</a>, and there are even independent <a href="http://rigetti.com/">quantum computer manufacturing groups</a>.</p>
<p>It seems like there are lots of options on which way to direct efforts in the quantum ML world, and with these recent developments on quantum ML techniques, the time appears to be right to be getting into quantum deep learning!</p>
<h2 id="appendix">Appendix <a id="appendix"></a></h2>
<p>More interesting quantum machine learning papers:</p>
<ul>
<li><a href="https://scirate.com/arxiv/1611.09347">1611.09347 - Quantum Machine Learning</a> (most recent review)</li>
<li><a href="https://scirate.com/arxiv/1610.08251">1610.08251 - Quantum-enhanced machine learning</a></li>
<li><a href="https://scirate.com/arxiv/1605.05370">1605.05370 - Training A Quantum Optimizer</a></li>
<li><a href="https://scirate.com/arxiv/1603.08675">1603.08675 - Quantum Recommender Systems</a></li>
<li><a href="https://scirate.com/arxiv/1512.06069">1512.06069 - Demonstration of quantum advantage in machine learning</a></li>
<li><a href="https://scirate.com/arxiv/1512.02900">1512.02900 - Advances in quantum machine learning</a></li>
<li><a href="https://scirate.com/arxiv/1611.08104">1611.08104 - Quantum Enhanced Inference in Markov Logic Networks</a></li>
<li><a href="https://scirate.com/arxiv/1609.02542">1609.02542 - Quantum-assisted learning of graphical models with arbitrary pairwise connectivity</a></li>
<li><a href="https://scirate.com/arxiv/1609.06935">1609.06935 - Quantum Neural Machine Learning - Backpropagation and Dynamics</a></li>
<li><a href="https://scirate.com/arxiv/1606.02318">1606.02318 - Solving the Quantum Many-Body Problem with Artificial Neural Networks</a></li>
<li>even more: <a href="https://scirate.com/search?utf8=%E2%9C%93&amp;q=quantum+machine+learning">SciRate - quantum machine learning</a>!</li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Here <em>efficient</em> means that the problem is in the complexity class caled <span class="math inline">\(\textbf{P}\)</span>. Problems that are efficient for quantum computers are in the complexity class <span class="math inline">\(\textbf{BQP}\)</span>. One of the main outstanding questions in the field is “Are quantum computers more powerful than classical ones?” and this can be phrased as comparing the class <span class="math inline">\(\textbf{P}\)</span> and <span class="math inline">\(\textbf{BQP}\)</span>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><em>“Something like” x</em> here is a very informal term for the more formal statement that the running time is <span class="math inline">\(O(x)\)</span>. See <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big O Notation</a> for more.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
]]></summary>
</entry>
<entry>
    <title>50 bad maths and programming jokes</title>
    <link href="https://silky.github.io/posts/2016-02-22-bad-maths-and-programming-jokes.html" />
    <id>https://silky.github.io/posts/2016-02-22-bad-maths-and-programming-jokes.html</id>
    <published>2016-02-22T00:00:00Z</published>
    <updated>2016-02-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on February 22, 2016
    
        by Noon van der Silk
    
</div>

<p>For the past few months at work we’ve been putting up a Chalkboard in front of the office with jokes on it.</p>
<div class="figure">
<img src="/images/brunch-and-bound.png" />

</div>
<p>Today marks the 50th joke, so to celebrate I’m writing up the complete list. Most of the jokes here were ones we made up without looking at the internet; but occasionally, in an effort to have two new jokes every day, we picked some classics.</p>
<blockquote>
<p>Q: What kind of parade did the astronauts throw for the computers after the mission?</p>
<p>A: A Turing tape parade!</p>
</blockquote>
<blockquote>
<p>Q: Why was the maths book sad?</p>
<p>A: It had too many problems.</p>
</blockquote>
<blockquote>
<p>Q: What did the AI say to the category theorist?</p>
<p>A: Does not commute!</p>
<p><small>(from <a href="https://andy.kitchen">Andy Kitchen</a>)</small></p>
</blockquote>
<blockquote>
<p>Q: How did the OR programmer solve a MIP while also eating?</p>
<p>A: By using a brunch and bound technique.</p>
</blockquote>
<blockquote>
<p>[“hip”, “hip”]</p>
</blockquote>
<blockquote>
<p>Q: What do measure theorists and programmers have in common?</p>
<p>A: They both enjoy continuous integration.</p>
</blockquote>
<blockquote>
<p>Old mathematicians never die, they just lose some of their functions.</p>
</blockquote>
<blockquote>
<p>Q: Why did the computer keep sneezing?</p>
<p>A: It had a virus.</p>
</blockquote>
<blockquote>
<p>Q: Why wasn’t the complex beer successful?</p>
<p>A: People had trouble ordering it!</p>
</blockquote>
<blockquote>
<p>Q: Why did the functional programmer return her TV?</p>
<p>A: Because it was immutable.</p>
</blockquote>
<blockquote>
<p>Q: What do ruby and librarians have in common?</p>
<p>A: They both have explicit return policies.</p>
</blockquote>
<blockquote>
<p>A shepherd was out in the field counting her sheep; she counted 96 but when she rounded them up she had 100.</p>
<p><small>(from <a href="http://www.twolostboys.com.au/">Two Lost Boys</a>)</small></p>
</blockquote>
<blockquote>
<p>Q: Why was the computer owner so successful at sheep husbandry?</p>
<p>A: She had excellent RAM.</p>
</blockquote>
<blockquote>
<p>Q: Why couldn’t the formal system complete it’s homework?</p>
<p>A: It was trying to be consistent.</p>
</blockquote>
<blockquote>
<p>404: Joke Not Found.</p>
</blockquote>
<blockquote>
<p>Q: How does a lumberjack mathematician cut down trees?</p>
<p>A: With her Axiom.</p>
</blockquote>
<blockquote>
<p>Q: Why did the programmer go to her bookshelf before leaving her house?</p>
<p>A: She needed to get her keys from the dictionary.</p>
</blockquote>
<blockquote>
<p>Q: Why don’t you want to fight an OR consultant?</p>
<p>A: They are experts at duals.</p>
</blockquote>
<blockquote>
<p>Q: What did the Linux system administer for the programmer’s head cold?</p>
<p>A: Sudo ephedrine</p>
</blockquote>
<blockquote>
<p>Q: How did the physicist fix her car when it was failing intermittently?</p>
<p>A: She used statistical mechanics!</p>
</blockquote>
<blockquote>
<p>Q: Why was the bad python programmer so rich?</p>
<p>A: Because everytime his code failed he got a raise.</p>
</blockquote>
<blockquote>
<p>Q: What do python programmers and event planners have in common?</p>
<p>A: They both like to decorate functions.</p>
</blockquote>
<blockquote>
<p>Q: Why is 0 the boss?</p>
<p>A: Because no other number can go above it!</p>
</blockquote>
<blockquote>
<p>Q: What did the mathematician say when they discovered a new prime number?</p>
<p>A: That’s odd.</p>
</blockquote>
<blockquote>
<p>Q: Why did the low-rank matrix go to the psychologist?</p>
<p>A: Because it was having an identity crisis!</p>
</blockquote>
<blockquote>
<p>Q: What is a floating point numbers favourite type of tennis?</p>
<p>A: Doubles!</p>
</blockquote>
<blockquote>
<p>Q: What does a blender and the Kalman filter hav in common?</p>
<p>A: They both perform a smoothing function!</p>
</blockquote>
<blockquote>
<p>Q: What is the mathematicians favourite kitchen item?</p>
<p>A: Derivasieve.</p>
</blockquote>
<blockquote>
<p>Q: Why don’t elephants use computers?</p>
<p>A: Scared of the mouse.</p>
</blockquote>
<blockquote>
<p>Q: Why was the OR consultant unwell?</p>
<p>A: She want on a benders.</p>
</blockquote>
<blockquote>
<p>Q: What is a statisticians favourite genre of music?</p>
<p>A: Drum and Bayes.</p>
</blockquote>
<blockquote>
<p>Q: What is a pet store operatores favourite state in a multiplayer game?</p>
<p>A: The Parrot optimal state.</p>
</blockquote>
<blockquote>
<p>Q: What is the enterprise java programmers favourite business book?</p>
<p>A: Scalaing up!</p>
</blockquote>
<blockquote>
<p>Q: What function is a tree hugger most concerned by?</p>
<p>A: <span class="math inline">\(\log(n)\)</span>.</p>
</blockquote>
<blockquote>
<p>Q: What is a garbologists favourite optimisation problem?</p>
<p>A: Bin packing.</p>
</blockquote>
<blockquote>
<div class="figure">
<img src="/images/giraph.png" />

</div>
</blockquote>
<blockquote>
<p>Q: What is a choirs favourite design pattern?</p>
<p>A: The <em>Sing</em>leton pattern!</p>
</blockquote>
<blockquote>
<p>Q: What do you call a mathematician that has lots of statues in her garden?</p>
<p>A: Polygnomial.</p>
</blockquote>
<blockquote>
<p>Q: What do fashion designers and Haskell programmers have in common?</p>
<p>A: They love pattern matching!</p>
</blockquote>
<blockquote>
<p>Q: How did the mathematician impress at the dance party?</p>
<p>A: By showing off her step function!</p>
</blockquote>
<blockquote>
<p>No joke provided; the Curry-Howard isomorphism allows us to generate a programming joke from the maths joke.</p>
</blockquote>
<blockquote>
<p>Q: Why was the mathematician unhappy when she turned 24?</p>
<p>A: She now had a lot of factors to consider.</p>
</blockquote>
<blockquote>
<p>Q: Why was the programmer so poor?</p>
<p>A: Syn<em>tax</em>.</p>
</blockquote>
<blockquote>
<p>Q: Why was the ML programmer late to the conference?</p>
<p>A: She spent too much time in the “train” stage.</p>
</blockquote>
<blockquote>
<p>Q: What number is good value?</p>
<p>A: 241</p>
<p>Exercise: What number is best value?</p>
</blockquote>
<blockquote>
<p>Q: Why couldn’t the python programmer get into her house?</p>
<p>A: Key error.</p>
</blockquote>
<blockquote>
<p>Q: How did the programmer get out of the deep end of the pool?</p>
<p>A: She made a pull request!</p>
</blockquote>
<blockquote>
<p>Q: Why was the ML researcher tired of shopping?</p>
<p>A: She was overfitting.</p>
</blockquote>
<blockquote>
<p>Q: How did the programmer get to the bottom of the ocean?</p>
<p>A: By sub-routine!</p>
</blockquote>
<blockquote>
<p>Q: How do you order citrus?</p>
<p>A: Use the real number lime.</p>
</blockquote>
]]></summary>
</entry>
<entry>
    <title>Building a windows-executable Haskell program with stack and AppVeyor</title>
    <link href="https://silky.github.io/posts/2016-01-05-build-windows-haskell-app-with-stack-and-appveyor.html" />
    <id>https://silky.github.io/posts/2016-01-05-build-windows-haskell-app-with-stack-and-appveyor.html</id>
    <published>2016-01-05T00:00:00Z</published>
    <updated>2016-01-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on January  5, 2016
    
        by Noon van der Silk
    
</div>

<p>In this post we’ll see how to setup a CI build that generates Windows executables for stack-based Haskell projects.</p>
<p>So imagine you love Haskell and you have written a Haskell program, you’ve hosted it on <a href="https://github.com">GitHub</a> and you’ve dilligently set up a CI build on <a href="https://travis-ci.org">Travis</a> that uses <a href="https://github.com/commercialhaskell/stack">stack</a> to build/test/etc.</p>
<p>Now, because stack is great and life is good, people can build your project from the source largely without issue. But suppose now that you’d like to provide Windows binaries for download. It so happens that we live in an age where this is completely automatable! Let’s see how.</p>
<p>The essence of my approach is to use the CI system <a href="http://www.appveyor.com/">AppVeyor</a> (essentially like a Travis for Windows), and the following <code>appveyor.yml</code> file (full file below, I’ll go through details next):</p>
<div class="sourceCode"><table class="sourceCode yaml numberLines"><tr class="sourceCode"><td class="lineNumbers"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="sourceCode"><pre><code class="sourceCode yaml"><span class="fu">build:</span> off

<span class="fu">before_build:</span>
<span class="kw">-</span> <span class="fu">curl -ostack.zip -L --insecure http:</span>//www.stackage.org/stack/windows-i386
<span class="kw">-</span> 7z x stack.zip stack.exe
<span class="kw">-</span> <span class="fu">sed -i &#39;s/git@github.com:</span>/https:\/\/github.com\//&#39; .gitmodules
<span class="co"># Appveyor doesn&#39;t clone recursively.</span>
<span class="kw">-</span> git submodule update --init --recursive

<span class="fu">skip_tags:</span> true

<span class="fu">build_script:</span>
<span class="co"># Suppress output from stack setup, as there is a lot and it&#39;s not necessary.</span>
<span class="kw">-</span> stack setup --no-terminal &gt; nul
<span class="kw">-</span> stack build --only-snapshot --no-terminal
<span class="kw">-</span> stack --local-bin-path . install haskmas
<span class="co"># Set a magical environment variable</span>
<span class="kw">-</span> <span class="fu">cmd:</span> for /f %%i in (&#39;stack exec -- haskmas -v&#39;) do set HASKMAS_VERSION=%%i

<span class="fu">artifacts:</span>
<span class="kw">-</span> <span class="fu">path:</span> haskmas.exe

<span class="co"># Auto-deploy</span>
<span class="fu">deploy:</span>
  <span class="kw">-</span> <span class="fu">provider:</span> GitHub
    <span class="fu">tag:</span> <span class="st">&#39;haskmas-$(HASKMAS_VERSION)&#39;</span>
    <span class="fu">release:</span> <span class="st">&#39;Release haskmas-$(HASKMAS_VERSION)&#39;</span>
    <span class="fu">auth_token:</span>
      <span class="fu">secure:</span> FZXhwa1ucQwyFtswv/XNUJkclAxoz4YGGu69dSOEEkwG7Rlh/Gho66SJtOUJ57kN
    <span class="fu">artifact:</span> haskmas.exe
    <span class="fu">on:</span>
      <span class="fu">branch:</span> master</code></pre></td></tr></table></div>
<p>Details:</p>
<ul>
<li>Line 1 disables the <em>standard</em> build process which would use MSBuild.</li>
<li>Lines 3-8 obtain the stack executable, and also perform a small hack which converts my <code>ssh</code>-based git submodules to <code>https</code>-based ones, that can be cloned without needing to mess about with ssh keys.</li>
<li>Line 10 prevents AppVeyor from building when it sees a new tag (later in the script we end up making a new tag when we push a release)</li>
<li>Lines 12-16 perform the typical stack build, and also install the <code>haskmas.exe</code> file that we will mark as an artifact</li>
<li>Line 18 is a magic command that sets the environment variable <code>HASKMAS_VERSION</code> to the value of the output of the command <code>stack exec -- haskmas -v</code>. This is my “hack” to obtain the cabal-version of the <code>haskmas</code> library, which I use as part of the tag that gets released on the <a href="https://github.com/silky/haskmas/releases">GitHub releases page</a></li>
<li>Line 21 simply marks the <code>haskmas.exe</code> as an artifact; this means AppVeyor will hang on to it after the build completes.</li>
<li>and finally, lines 24-32 specify that, for each build that completes, AppVeyor should push a release with the tag <code>haskmas-&lt;cabal_version_of_haskmas&gt;</code> to the GitHub releases page! (Note: probably we would want to be a bit more elaborate about when we push to the releases page; making sure that we include proper release notes, etc.)</li>
</ul>
<p>You can see from the releases on the <code>haskmas</code> project istelf that I fumbled around with this setup a bit. Mostly I observed that the manual release process on AppVeyor doesn’t quite operate the way I’d’ve <a href="https://github.com/appveyor/ci/issues/593">hoped</a>; but in any case AppVeyor is a pretty convenient service; it’s very nice to see something for Windows in this space.</p>
<p>I based my configuration off of the one for the <a href="https://github.com/commercialhaskell/stack/blob/master/appveyor.yml">stack tool itself</a>. Note that there is some mention of caching in there that might speed up the build (my build takes ~17 minutes on AppVeyor compared to ~2 minutes on travis).</p>
<p>All-in-all, technical details about automatically pushing releases aside, AppVeyor+stack is a really nice way to build Windows binaries from exactly the same source as your linux binaries. The only outstanding item to do is to combine artifacts from travis and AppVeyor into a single entity that can be released dually; but on the other hand tooling could always be written to perform this semi-manually, from your working computer, when you are ready to release.</p>
<p>The repo is here: <a href="https://github.com/silky/haskmas">haskmas</a>. As a side benefit, I made the haskmas program take command line arguments to control how it operates! So now you don’t need to compile it to get a tree of arbitrary depth!</p>
]]></summary>
</entry>
<entry>
    <title>Happy Haskmas!</title>
    <link href="https://silky.github.io/posts/2015-12-18-happy-haskmas.html" />
    <id>https://silky.github.io/posts/2015-12-18-happy-haskmas.html</id>
    <published>2015-12-18T00:00:00Z</published>
    <updated>2015-12-18T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on December 18, 2015
    
        by Noon van der Silk
    
</div>

<p>At the last <a href="http://www.meetup.com/Melbourne-Haskell-Users-Group/events/222203592/">Melbourne Haskell Meetup</a> we got into the spirit by making <a href="https://github.com/imccoy/xmast">Christmas trees in Haskell</a>.</p>
<p>However, I recently have access to a 3D printer, and I’ve long wanted an excuse to try and use <a href="https://github.com/colah/ImplicitCAD">ImplicitCAD</a>, so I set about trying to make a 3D version of <a href="https://github.com/sordina">Lyndon</a>’s <a href="http://www.meetup.com/Melbourne-Haskell-Users-Group/photos/26573949/">logo</a>.</p>
<p>So of course, I love <a href="https://github.com/commercialhaskell/stack">stack</a> I created a new <code>simple</code> project with <code>stack new</code> and got started.</p>
<p>It turns out that <code>ImplicitCAD</code> has a pretty nice and reasonably intuitive interface (similar to the code that one would write into <a href="http://www.openscad.org/">OpenSCAD</a>).</p>
<p>I built the 3D version of the logo by moving around rectangles, and by extruding a hand-drawn shape.</p>
<p>The cool thing about generating this image in fully-feature programming language is that I can build a tree of any size I like!</p>
<p>Here’s the (pretty verbose) code that gets me a tree of arbitrary depth:</p>
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="ot">ntree ::</span> <span class="dt">Integer</span> <span class="ot">-&gt;</span> <span class="dt">SymbolicObj3</span>
ntree n <span class="fu">=</span> finalObj
  <span class="kw">where</span>
      dec     <span class="fu">=</span> <span class="fl">0.8</span>
      ratios  <span class="fu">=</span> <span class="dv">0</span> <span class="fu">:</span> [dec<span class="fu">^</span>j <span class="fu">|</span> j <span class="ot">&lt;-</span> [<span class="dv">0</span><span class="fu">..</span>(n<span class="fu">-</span><span class="dv">2</span>)]]
      <span class="co">-- build up logo structure</span>
      ((lx, ly, lz), objs) <span class="fu">=</span> foldl f ((<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), []) (zip [<span class="dv">0</span><span class="fu">..</span>(n<span class="fu">-</span><span class="dv">1</span>)] ratios)
      <span class="co">-- position of logos</span>
      (x,y,z) <span class="fu">=</span> (<span class="dv">40</span>, <span class="dv">4</span>, <span class="dv">0</span>)
<span class="ot">      f ::</span> ((ℝ, ℝ, ℝ), [<span class="dt">SymbolicObj3</span>]) <span class="ot">-&gt;</span> (<span class="dt">Integer</span>, <span class="dt">Float</span>) <span class="ot">-&gt;</span> ((ℝ, ℝ, ℝ), [<span class="dt">SymbolicObj3</span>])
      f ((x&#39;, y&#39;, z&#39;), xs) (j, r) <span class="fu">=</span>
                <span class="kw">let</span> newPos <span class="fu">=</span> (x&#39; <span class="fu">+</span> r<span class="fu">*</span>x, y&#39; <span class="fu">+</span> r<span class="fu">*</span>y, z&#39; <span class="fu">+</span> r<span class="fu">*</span>z)
                    s      <span class="fu">=</span> dec <span class="fu">^</span> j
                    loc    <span class="fu">=</span> <span class="kw">if</span> (even j) <span class="kw">then</span> <span class="dt">R</span> <span class="kw">else</span> <span class="dt">L</span>
                    obj3   <span class="fu">=</span> translate newPos <span class="fu">$</span> scale (s, s, s) (logoBauble loc)
                 <span class="kw">in</span> (newPos, obj3 <span class="fu">:</span> xs)
      <span class="co">-- star</span>
      (a,b,c)   <span class="fu">=</span> (<span class="fl">40.5</span>, <span class="fl">24.5</span>, <span class="dv">0</span>)
      starScale <span class="fu">=</span> dec <span class="fu">**</span> (fromIntegral (n<span class="fu">-</span><span class="dv">3</span>))
      posScale  <span class="fu">=</span> dec <span class="fu">**</span> (fromIntegral n)
      starObj   <span class="fu">=</span> translate (lx <span class="fu">+</span> (posScale <span class="fu">*</span> a), ly <span class="fu">+</span> (posScale <span class="fu">*</span> b), lz <span class="fu">+</span> (posScale <span class="fu">*</span> c))
                    <span class="fu">$</span> scale (starScale, starScale, starScale) star
      finalObj <span class="fu">=</span> union (starObj <span class="fu">:</span> objs)</code></pre></div>
<p>Running this with <span class="math inline">\(n = 5\)</span> gives result in the following render in OpenSCAD:</p>
<div class="figure">
<img src="/images/tree-5.png" />

</div>
<p>So there you have it! You can view the source code here: <a href="https://github.com/silky/haskmas">github.com/silky/haskmas</a> or download a ready-to-print STL from <a href="http://www.thingiverse.com/thing:1187442">Thingiverse</a>.</p>
<p>Have a happy Haskmas! :)</p>
]]></summary>
</entry>
<entry>
    <title>Super Reference! Web Haskell-based reference management</title>
    <link href="https://silky.github.io/posts/2015-10-14-super-reference-haskell-reference-manager.html" />
    <id>https://silky.github.io/posts/2015-10-14-super-reference-haskell-reference-manager.html</id>
    <published>2015-10-14T00:00:00Z</published>
    <updated>2015-10-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on October 14, 2015
    
        by Noon van der Silk
    
</div>

<p>Today I’m announcing a (very) alpha version of my web-based reference management system, <a href="https://github.com/silky/super-reference">super-reference</a>!</p>
<p>Super-reference is a system which:</p>
<ol style="list-style-type: decimal">
<li>Reads a bibtex file and lets you search the bibtex entries in it</li>
<li>Provides an interface to open associated PDFs or visit associated links</li>
<li>Maintains a list of ‘currently reading’ PDFs by synching a folder (for me, a dropbox folder)</li>
</ol>
<p>Here’s a screenshot of the main (only) page:</p>
<div class="figure">
<img src="https://raw.github.com/silky/super-reference/master/another_screenshot.png" />

</div>
<p>Super-reference is built around my workflow for getting the latest papers.</p>
<p>A high-level overview of my workflow is:</p>
<ol style="list-style-type: decimal">
<li>Find an interesting paper</li>
<li>Obtain the pdf file for this paper, (preferably from <a href="https://arxiv.org">arXiv</a>)</li>
<li>Save this pdf on my computer, and get the <code>bibtex</code> data for the file somehow</li>
<li>At some point in the future, be interested in finding this PDF by searching for the title, or browsing through a list</li>
</ol>
<p>All the while I’d like to maintain a list of “papers I’m currently reading” and have them available on my tablet.</p>
<p>Items 1-3 take place <em>outside</em> of super-reference. My workflow for finding new papers and saving them on my computer is a little specialised, but happily you don’t need to follow this protocol if you want to get utility out of super-reference — you simply need a <code>bibtex</code> file to point it at.</p>
<p>Here’s my new paper obtaining workflow (yours may be different):</p>
<ol style="list-style-type: decimal">
<li>Browse <a href="https://scirate.com">SciRate</a> regularly, and “scite” interesting papers</li>
<li>Periodically run <a href="https://github.com/silky/scirate3_scraper">scirate3_scaper</a> to bring down all the papers I’ve scited recently, and their bibtex entries</li>
<li>Combine all these bibtex entries ino my <em>One True</em> bibtex file</li>
</ol>
<h2 id="using-super-reference">Using super-reference</h2>
<p>Let’s suppose now you have a <em>One True</em> bibtex file called <code>all.bib</code>.</p>
<p>Grab yourself down a copy of the repository by following the <a href="https://github.com/silky/super-reference/#installation">instructions</a> to configure it to point to this bibtex file.</p>
<p>Once you have the environment set up you can run a dev server with <code>yesod devel</code>. You will then be able to visit the website! Supposing you pointed the config file at your <code>all.bib</code> file, you will then be looking at all your interesting papers! If there’s a link associated with the entry, a link will be displayed, and if there is a PDF file, clicking on the entry name will open the PDF (with it’s location given by the <code>file</code> entry in the relevant bibtex entry).</p>
<p>You can click the <code>star</code> link to move the PDF up into the “currently reading” section. (Note: At the moment there is no visual indication of this, but it will be shown next time the page loads.)</p>
<h2 id="improvements">Improvements</h2>
<p>Currently there is a lot of outstanding work to do on super-reference; but it’s in a working state for me, so I thought I should release it.</p>
<p>If you have any feature requests/improvements/etc feel free to log an issue (or a pull request) over at the repository: <a href="https://github.com/silky/super-reference">super-reference</a>.</p>
]]></summary>
</entry>
<entry>
    <title>Versioned LyX documents</title>
    <link href="https://silky.github.io/posts/2015-10-01-Makefile-for-versioned-lyx.html" />
    <id>https://silky.github.io/posts/2015-10-01-Makefile-for-versioned-lyx.html</id>
    <published>2015-10-01T00:00:00Z</published>
    <updated>2015-10-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on October  1, 2015
    
        by Noon van der Silk
    
</div>

<p>Oftentimes one needs to write a document with math symbols in it. The standard tool of choice is some variant of TeX, either writing it online in one of the growing-list of collaborative editors:</p>
<ul>
<li><a href="https://www.overleaf.com/">Overleaf</a></li>
<li><a href="https://www.sharelatex.com/">ShareLaTeX</a></li>
<li><a href="https://www.authorea.com/">Authorea</a></li>
</ul>
<p>But one program, that runs locally, that I can’t stop using is <a href="http://www.lyx.org/">LyX</a>.</p>
<p>I really like LyX because of the “What-you-see-is-(pretty much)-what-you-get” nature of it.</p>
<p>One thing I wanted to share was a small technique that I used to get a version number in all of the pdfs that I generated from my LyX documents. The idea was that when I sent my document to obtain feedback from various interested parties, I could easily see which version they had commented on.</p>
<p>What I wanted as a footer that would be included on every page, that contained the version number.</p>
<p>The approach is:</p>
<ol style="list-style-type: decimal">
<li>In the “LaTeX Preamble” setting of the LyX document, include (something like)</li>
</ol>
<pre><code>\usepackage{fancyhdr}
\pagestyle{fancy}
\cfoot{\tiny{|VERSION|}}
\rfoot{\thepage}
\rhead{}</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Build your LyX documents by the command line with a <code>Makefile</code>. My <code>Makefile</code> looks like so:</li>
</ol>
<pre><code>BUILD_NUMBER_FILE := build-number.txt
BUILD_NUMBER      := $(shell cat $(BUILD_NUMBER_FILE))
BUILD_DATE        := $(shell date +%d%b%Y)
VER_STRING        := $(BUILD_DATE)-build$(BUILD_NUMBER)
LYXFILE           := coolness
TEMPDIR           := /tmp

all: pdf

# Switch in the new version number, compile with LyX and
# bring it here.
pdf: buildnumber
	sed &quot;s/|VERSION|/$(VER_STRING)/g&quot; $(LYXFILE).lyx &gt;$(TEMPDIR)/$(LYXFILE).lyx
	lyx -e pdf2 $(TEMPDIR)/$(LYXFILE).lyx
	cp $(TEMPDIR)/$(LYXFILE).pdf .

# Build number file. Increment each build.
buildnumber:
	@if ! test -f $(BUILD_NUMBER_FILE); then echo 0 &gt; $(BUILD_NUMBER_FILE); fi
	@echo $$(($$(cat $(BUILD_NUMBER_FILE)) + 1)) &gt; $(BUILD_NUMBER_FILE)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Build with the <code>make</code> command and profit!</li>
</ol>
<p>Note that there is a <code>build-number.txt</code> file that is incremented on each build, so you don’t need to do that manually.</p>
<p>I’ve put together a sample project <a href="https://gist.github.com/silky/9accc6e6a5dbbc029669">here</a>, so you can clone that gist and type <code>make</code> and see it in action!</p>
]]></summary>
</entry>
<entry>
    <title>GHCi Colouriser</title>
    <link href="https://silky.github.io/posts/2015-09-22-ghci-colouriser.html" />
    <id>https://silky.github.io/posts/2015-09-22-ghci-colouriser.html</id>
    <published>2015-09-22T00:00:00Z</published>
    <updated>2015-09-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on September 22, 2015
    
        by Noon van der Silk
    
</div>

<p>Behold, a colourful GHCi (<a href="https://github.com/silky/ghci-color">install it for yourself</a>):</p>
<div class="figure">
<img src="https://raw.github.com/silky/ghci-color/master/cap2.png" />

</div>
<p>This is done by using a simple little <code>sed</code> wrapper around the ordinary <code>ghci --interactive</code>, see <a href="https://github.com/silky/ghci-color/blob/master/ghci-color">here</a> for the script.</p>
<p>Note in particular the quirk that we must capture any <code>SIGINT</code> that gets sent through and discard it, when we are invoking <code>sed</code>, otherwise <code>sed</code> itself will quit and our GHCi session will break.</p>
<p>You can use it <code>cabal repl</code> (being mindful of <a href="https://github.com/haskell/cabal/issues/1905">this bug</a>) by using <code>cabal repl --with-ghc=ghci-color</code>. I’ve bound an alias <code>repl</code> to this.</p>
<p>(Note: original credit for this goes to <a href="https://github.com/rhysd/">rhysd</a>)</p>
]]></summary>
</entry>
<entry>
    <title>Fresh Prince of Bell Pair</title>
    <link href="https://silky.github.io/posts/2015-05-29-fresh-prince-of-bell-pair.html" />
    <id>https://silky.github.io/posts/2015-05-29-fresh-prince-of-bell-pair.html</id>
    <published>2015-05-29T00:00:00Z</published>
    <updated>2015-05-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on May 29, 2015
    
        by Noon van der Silk
    
</div>

<p>Written for my Masters completion talk. <a href="https://vimeo.com/129394232">Video</a>.</p>
<h2 id="lyrics">Lyrics</h2>
<blockquote>
<p>now this is a story, all about how</p>
</blockquote>
<blockquote>
<p>my life got spun, both up and down</p>
</blockquote>
<div class="figure">
<img src="/images/p1.png" />

</div>
<blockquote>
<p>and i’d like to take a minute, just sit right there</p>
</blockquote>
<blockquote>
<p>and i’ll tell you how i became the prince, of the state called <a href="http://en.wikipedia.org/wiki/Bell_state">bell pair</a></p>
</blockquote>
<div class="figure">
<img src="/images/p2.png" />

</div>
<blockquote>
<p>in programming languages, born and raised, on the computer, was where i spent most of my days</p>
</blockquote>
<blockquote>
<p>typing out, compiling, building some tools, and all surfing the internet looking for news</p>
</blockquote>
<blockquote>
<p>when a couple of guys who seemed kinda fine, started making trouble in polynomial time!</p>
</blockquote>
<div class="figure">
<img src="/images/p3.png" />

</div>
<blockquote>
<p>they got in one little fight (BQP vs BPP) and everyone got scared,</p>
</blockquote>
<div class="figure">
<img src="/images/p4.png" />

</div>
<blockquote>
<p>someone said: we’re going to build a quantum computer, so you better be prepared!</p>
</blockquote>
<div class="figure">
<img src="/images/p5.png" />

</div>
]]></summary>
</entry>

</feed>
