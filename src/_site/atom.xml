<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>silky.github.io</title>
    <link href="https://silky.github.io/atom.xml" rel="self" />
    <link href="https://silky.github.io" />
    <id>https://silky.github.io/atom.xml</id>
    <author>
        <name>Noon van der Silk</name>
        <email>noonsilk+-noonsilk@gmail.com</email>
    </author>
    <updated>2018-11-19T00:00:00Z</updated>
    <entry>
    <title>Reliable training hack on the Google Colaboratory</title>
    <link href="https://silky.github.io/posts/2018-11-19-reliable-training-hack-on-google-colaboratory.html" />
    <id>https://silky.github.io/posts/2018-11-19-reliable-training-hack-on-google-colaboratory.html</id>
    <published>2018-11-19T00:00:00Z</published>
    <updated>2018-11-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on November 19, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>Google’s <a href="https://colab.research.google.com/notebooks/welcome.ipynb#recent=true">Colaboratory</a> is a hosted notebook environment, with access to GPUs, and even TPUs!</p>
</div>
<div>
<p>It’s really quite handy, but by far the biggest downside is that the sessions time out. It makes sense; I’m sure even Google can’t give out an unlimited amount of compute-resources for free to every person.</p>
</div>
<div>
<h3 id="backgroundproblem">Background/Problem</h3>
</div>
<div>
<p>On the weekend, I wanted to train a few <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn">sketch-rnn models</a> on the <a href="https://quickdraw.withgoogle.com/data">quickdraw data</a>.</p>
</div>
<div>
<p>Naively, I figured this would be really easy with Google colab. While it was straightforward to start training, what I noticed is that getting data on to and off of the instance was frustrating, and the timeouts blocked me from getting a good amount of training time.</p>
</div>
<div>
<h3 id="solution">Solution</h3>
</div>
<div>
<p>Happily, colab supports very nice integration with Google services, so my plan was:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
Download data from Google Cloud Platform (GCP),
</div></li>
<li><div>
Train, or continue training,
</div></li>
<li><div>
Push a checkpoint to Google Drive occasionally,
</div></li>
<li><div>
Repeat until happy.
</div></li>
</ol>
</div>
<div>
<p>Here’s how it looks, in code:</p>
</div>
<div>
<p><strong>Download data from GCP</strong></p>
</div>
<div>
<p>As I’m working with the quickdraw data, it’s already on the Google Cloud Platform, so this was very easy. In a cell, I simply ran the following to get the “eye” quickdraw data:</p>
</div>
<div>
<pre><code>!gsutil cp gs://quickdraw_dataset/sketchrnn/eye.npz .</code></pre>
</div>
<div>
<p>(Note that the <code>gsutil</code> command is already installed on the instance.)</p>
</div>
<div>
<p><strong>Train, or continue training, and save to Drive</strong></p>
</div>
<div>
<p>As I’m using the <code>sketch_rnn</code> model, I first simply install <code>magenta</code> (and I have to pick a Python 2 environment.)</p>
</div>
<div>
<pre><code>!pip install magenta</code></pre>
</div>
<div>
<p>Now, there’s some considerations. Recalling that I’m going to be pushing my checkpoints to Google Drive, I need to authenticate with Google Drive. This is how that looks:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> google.colab <span class="im">import</span> auth
auth.authenticate_user()</code></pre></div>
</div>
<div>
<p>Then you’ll be prompted to copy in a code. Once that’s done, you can connect to Google Drive like so:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> googleapiclient.discovery <span class="im">import</span> build
drive_service <span class="op">=</span> build(<span class="st">&#39;drive&#39;</span>, <span class="st">&#39;v3&#39;</span>)</code></pre></div>
</div>
<div>
<p>Now, if I’m training from scratch, I’ll run something like this:</p>
</div>
<div>
<pre><code>!sketch_rnn_train --log_root=logs --data_dir=./ --hparams=&quot;data_set=[eye.npz],num_steps=501&quot;</code></pre>
</div>
<div>
<p>This will run for however long, and utlimately produce checkpoints in the <code>./logs</code> folder, supposing that <code>eye.npz</code> exists in the present directory.</p>
</div>
<div>
<p>Once that’s completed, I start my main training-pushing loop. Firstly, there’s a bit of busywork to zip files, get the latest checkpoint number, and upload it to Google Drive:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> os
<span class="im">import</span> zipfile
<span class="im">from</span> googleapiclient.http <span class="im">import</span> MediaFileUpload

<span class="kw">def</span> get_largest_num (<span class="bu">dir</span><span class="op">=</span><span class="st">&quot;logs&quot;</span>, prefix<span class="op">=</span><span class="st">&quot;vector&quot;</span>):
  
  files <span class="op">=</span> os.listdir(<span class="bu">dir</span>)
  
  biggest <span class="op">=</span> <span class="dv">0</span>
  
  <span class="cf">for</span> f <span class="kw">in</span> files:
    <span class="cf">if</span> f.startswith(prefix):
      k <span class="op">=</span> <span class="bu">int</span>( f.split(<span class="st">&quot;.&quot;</span>)[<span class="dv">0</span>].split(<span class="st">&quot;-&quot;</span>)[<span class="dv">1</span>] ) 
      <span class="cf">if</span> k <span class="op">&gt;</span> biggest:
        biggest <span class="op">=</span> k
  
  <span class="cf">return</span> biggest


<span class="kw">def</span> zip_model (name, k):
  sk     <span class="op">=</span> <span class="bu">str</span>(k)
  zipobj <span class="op">=</span> zipfile.ZipFile(name <span class="op">+</span> <span class="st">&quot;.zip&quot;</span>, <span class="st">&quot;w&quot;</span>, zipfile.ZIP_DEFLATED)

  files <span class="op">=</span> [ <span class="st">&quot;checkpoint&quot;</span>
          , <span class="st">&quot;model_config.json&quot;</span>
          , <span class="st">&quot;vector-&quot;</span> <span class="op">+</span> sk <span class="op">+</span> <span class="st">&quot;.meta&quot;</span>
          , <span class="st">&quot;vector-&quot;</span> <span class="op">+</span> sk <span class="op">+</span> <span class="st">&quot;.index&quot;</span>
          , <span class="st">&quot;vector-&quot;</span> <span class="op">+</span> sk <span class="op">+</span> <span class="st">&quot;.data-00000-of-00001&quot;</span>]
  
  <span class="cf">for</span> f <span class="kw">in</span> files:
    zipobj.write(<span class="st">&quot;logs/&quot;</span> <span class="op">+</span> f, f)



<span class="kw">def</span> upload_to_drive (name<span class="op">=</span><span class="st">&quot;model.zip&quot;</span>):
  file_metadata <span class="op">=</span> {
    <span class="st">&quot;name&quot;</span>:     name,
    <span class="st">&quot;mimeType&quot;</span>: <span class="st">&quot;binary/octet-stream&quot;</span> }

  media <span class="op">=</span> MediaFileUpload(name, 
                          mimetype<span class="op">=</span><span class="st">&quot;binary/octet-stream&quot;</span>,
                          resumable<span class="op">=</span><span class="va">True</span>)

  created <span class="op">=</span> drive_service.files().create(body<span class="op">=</span>file_metadata,
                                         media_body<span class="op">=</span>media,
                                         fields<span class="op">=</span><span class="st">&quot;id&quot;</span>).execute()
  file_id <span class="op">=</span> created.get(<span class="st">&quot;id&quot;</span>)
  <span class="cf">return</span> file_id</code></pre></div>
</div>
<div>
<p>Then, the main loop:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">iterations <span class="op">=</span> <span class="dv">200</span>
<span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(iterations):
  <span class="bu">print</span>(<span class="st">&quot;Iteration &quot;</span> <span class="op">+</span> <span class="bu">str</span>(k))
  cmd <span class="op">=</span> <span class="st">&#39;sketch_rnn_train --log_root=logs --resume_training --data_dir=./ &#39;</span> <span class="op">+</span> <span class="op">\</span>
        <span class="co">&#39; --hparams=&quot;data_set=[eye.npz],num_steps=1001&quot;&#39;</span>
  x <span class="op">=</span> os.system(cmd)
  zip_model(<span class="st">&quot;model&quot;</span>, get_largest_num())
  upload_to_drive()</code></pre></div>
</div>
<div>
<p>So, all that does is run the main training command, to reload the model from the latest checkpoint and continue training, then zips and uploads!</p>
</div>
<div>
<p>Set the iterations to whatever you wish; chances are your instance will never run for that long anyway; the main point is to push up the checkpoints every-so-often (for me, every 1000 steps of the sketch_rnn model; which takes about 1 hour or so, depending on params.)</p>
</div>
<div>
<p><strong>Brining down the most recent Drive checkpoint</strong></p>
</div>
<div>
<p>Now, when your instance goes away, you’ll need to bring down the most recent checkpoint <em>from</em> Drive. I did this somewhat manually, but it works well enough:</p>
</div>
<div>
<pre><code># Mount Google Drive as a folder
from google.colab import drive
drive.mount(&#39;/content/gdrive&#39;)</code></pre>
</div>
<div>
<pre><code># Extract latest model zip file
!cp /content/gdrive/My\ Drive/model\ \(3\).zip logs/model.zip &amp;&amp; cd logs &amp;&amp; unzip model.zip</code></pre>
</div>
<div>
<p>Note that Google Drive numbers all the files as copies, like “model (4).zip”, “model (5).zip”, when you upload the same name. On the web interface, it only shows one file, but gives you history. Do as you wish here; I was a bit lazy.</p>
</div>
<div>
<h3 id="thats-it">That’s it!</h3>
</div>
<div>
<p>Hope this helps you do some training!</p>
</div>
<div>
<p>You can read more about other ways to access data from Google Colaboratory <a href="https://colab.research.google.com/notebooks/io.ipynb">here</a>.</p>
</div>
]]></summary>
</entry>
<entry>
    <title>A quick note on budgeting ...</title>
    <link href="https://silky.github.io/posts/2018-11-09-quick-note-on-budgeting.html" />
    <id>https://silky.github.io/posts/2018-11-09-quick-note-on-budgeting.html</id>
    <published>2018-11-09T00:00:00Z</published>
    <updated>2018-11-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on November  9, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>In “<a href="https://www.goodreads.com/book/show/616875.The_Oregon_Experiment">The Oregon Experiment</a>”, the authors consider the following budgeting scenario.</p>
</div>
<div>
<p>Suppose you’re in the following situation: You have ~$2,500,000 that you’d like to allocate to construction projects in your community.</p>
</div>
<div>
<p>There are many ways you can allocate this money to projects of varying sizes. Consider the following options:</p>
</div>
<div>
<style type="text/css">
table.budget {
margin: 10px;
background: #eaeaea;
}
table.budget th {
border: 0;
margin: 0;
border-bottom: solid 1px gray;
}
table.budget td {
border: 0;
padding: 5px;
}
table.budget td.r {
text-align: right;
}
td.m, th.m { width: 100px; }
td.r, th.r { width: 150px; }
table.budget td.m {
text-align: center;
}
table.budget tr.total td {
border-top: solid 1px gray;
}
div.tables {
display: flex;
flex-direction: row;
flex-wrap: wrap;
justify-content: center;
}
div.tables div {
display: flex;
flex-direction: column;
}
</style>
</div>
<div>
<div class="tables">
<div>
<div>
<div>
<h3 id="option-1---all-projects-considered-equally">Option 1 - All projects considered equally</h3>
</div>
<div>
<table class="budget">
</div>
<div>
<tr>
</div>
<div>
<th>
</div>
<div>
category
</div>
<div>
</th>
</div>
<div>
<th class="m">
</div>
<div>
number of projects
</div>
<div>
</th>
</div>
<div>
<th class="r">
</div>
<div>
rough total cost based on averages
</div>
<div>
</th>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
A &lt; $1000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
B $1000-$10,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$5,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
C $10,000-$100,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$50,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
D $100,000-$1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
E &gt; $1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$2,000,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr class="total">
</div>
<div>
<td>
</div>
<div>
<b>totals</b>
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
5
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
~$2,600,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
</table>
</div>
</div>
</div>
<div>
<div>
<div>
<h3 id="option-2---projects-considered-unequally">Option 2 - Projects considered unequally</h3>
</div>
<div>
<table class="budget">
</div>
<div>
<tr>
</div>
<div>
<th>
</div>
<div>
category
</div>
<div>
</th>
</div>
<div>
<th class="m">
</div>
<div>
number of projects
</div>
<div>
</th>
</div>
<div>
<th class="r">
</div>
<div>
rough total cost based on averages
</div>
<div>
</th>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
A &lt; $1000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1000
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
B $1000-$10,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
100
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
C $10,000-$100,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
10
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
D $100,000-$1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
E &gt; $1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
⅒ th of a project
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr class="total">
</div>
<div>
<td>
</div>
<div>
<b>totals</b>
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
~1100
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$2,500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
</table>
</div>
</div>
</div>
<div>
<div>
<div>
<h3 id="option-3---a-middle-ground">Option 3 - A middle ground</h3>
</div>
<div>
<table class="budget">
</div>
<div>
<tr>
</div>
<div>
<th>
</div>
<div>
category
</div>
<div>
</th>
</div>
<div>
<th class="m">
</div>
<div>
number of projects
</div>
<div>
</th>
</div>
<div>
<th class="r">
</div>
<div>
rough total cost based on averages
</div>
<div>
</th>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
A &lt; $1000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
500
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$250,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
B $1000-$10,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
50
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$250,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
C $10,000-$100,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
10
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
D $100,000-$1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr>
</div>
<div>
<td>
</div>
<div>
E &gt; $1,000,000
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
1
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$1,000,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
<tr class="total">
</div>
<div>
<td>
</div>
<div>
<b>totals</b>
</div>
<div>
</td>
</div>
<div>
<td class="m">
</div>
<div>
~550
</div>
<div>
</td>
</div>
<div>
<td class="r">
</div>
<div>
$2,500,000
</div>
<div>
</td>
</div>
<div>
</tr>
</div>
<div>
</table>
</div>
</div>
</div>
</div>
</div>
<div>
<p>The main conclusion is that, for the same amount of money, we can chose to either support lots of small projects, or few total projects.</p>
</div>
<div>
<p>One of the main premises of the book, is that good change is made locally, by locals. In this way, schemes 2 and 3 are a <em>significant</em> improvement over Option 1.</p>
</div>
<div>
<p>One of the best initiatives that Victoria is doing along these lines is the “<a href="https://pickmyproject.vic.gov.au/">Pick My Project</a>” program.</p>
</div>
<div>
<p>However, I think it’s also interesting to think about this in relation to other areas:</p>
</div>
<div>
<ul>
<li><div>
Health: Should you make one big change? Or many small ones?
</div></li>
<li><div>
Programming: Should you write one big program? Or many little ones?
</div></li>
<li><div>
Management: Should you set big goals from the top? Or should you empower the people below you to set their own goals?
</div></li>
</ul>
</div>
]]></summary>
</entry>
<entry>
    <title>Simple Dance Booth Open-Sourced (based on TensorFlow.js demo)</title>
    <link href="https://silky.github.io/posts/2018-11-05-dance-booth-open-source.html" />
    <id>https://silky.github.io/posts/2018-11-05-dance-booth-open-source.html</id>
    <published>2018-11-05T00:00:00Z</published>
    <updated>2018-11-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on November  5, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>Over on the <a href="https://github.com/silverpond">Silverpond</a> GitHub account we recently open-sourced the little <a href="https://github.com/silverpond/dance-booth">dance-booth</a> project that we’ve been playing with for a while now.</p>
</div>
<div>
<p><img src="/images/dance-booth.jpg" width="600" /></p>
</div>
<div>
<p>It’s a very simple little wrapper around their <a href="https://github.com/tensorflow/tfjs-models/tree/master/posenet">PoseNet</a> demo.</p>
</div>
<div>
<p>It’s a neat little repo, that runs entirely offline, and, from a webcam or anything that can be accessed via the browser, can be used to capture dances in three forms:</p>
</div>
<div>
<ul>
<li><div>
The raw video from the webcam,
</div></li>
<li><div>
JSON data of the poses per frame,
</div></li>
<li><div>
Video of the skeleton dancing on the dance floor.
</div></li>
</ul>
</div>
<div>
<p>You’ll find all of these saved under the date-and-time in the <code>./saved-videos</code> folder. The JSON can be used to recreate the entire dance in any form you wish; it gives the coords of the various joints.</p>
</div>
<div>
<p>At the present moment it the dance capture only starts when the people in frame all raise their hands above their heads.</p>
</div>
<div>
<p>Feel free to change and play with as you wish!</p>
</div>
]]></summary>
</entry>
<entry>
    <title>QML+ Conference Review & Current State of Quantum Machine Learning</title>
    <link href="https://silky.github.io/posts/2018-10-23-qml-plus-conference-review-of-work-on-quantum-machine-learning.html" />
    <id>https://silky.github.io/posts/2018-10-23-qml-plus-conference-review-of-work-on-quantum-machine-learning.html</id>
    <published>2018-10-23T00:00:00Z</published>
    <updated>2018-10-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on October 23, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p><small>(This series of posts originally appeared on the <a href="https://silverpond.com.au/2018/09/17/qml-plus-2018-day-1/">Silverpond blog</a>)</small></p>
</div>
<div>
<h2 id="day-1">Day 1</h2>
</div>
<div>
<center>
</div>
<div>
<img src="/images/innsbruck.jpg" width="800" />
</div>
<div>
</center>
</div>
<div>
<p>Well, we made it to Innsbruck, Austria!</p>
</div>
<div>
<p>It was a huge journey to get here, and I have to tell you, Austria in general, and Innsbruck in particular, is absolutely beautiful.</p>
</div>
<div>
<p>On the train ride from Vienna to Salzburg, we spent most of the time looking out of the window taking photos. The weather is amazing; it’s perfectly warm and sunny, and it’s amazing to walk around the town and just see mountains everywhere.</p>
</div>
<div>
<p>But, I’m here, of course, on business, and in particular, primarily to attend the QML+ – <em><a href="https://www.uibk.ac.at/congress/quantum-machine-learning-plus/index.html.en">Quantum Machine Learning … Plus</a></em> – conference.</p>
</div>
<div>
<p>It’s the night of Day 1, so here’s a review of what happened:</p>
</div>
<div>
<h3 id="opening-talk-why-qml">Opening Talk: Why QML+?</h3>
</div>
<div>
<p><em>by Hans Briegel</em></p>
</div>
<div>
<p>Hans Briegel, famous partly for his involvement measurement-based quantum computation (and of particular relevance to me, because this was part of what my Masters work was about) gave an overview talk about why we might care to think about how quantum computing could play a role in machine learning.</p>
</div>
<div>
<p>I quite enjoyed one of his ideas, which is thinking about how “Embodied AI” relates to the ideas of “information is physical” insofaras both imply that in order to think about the primary subject, we need to involve physics. This has been particularly fruitful in physics and information theory, and relates to some very far-reaching ideas, such as <a href="https://en.wikipedia.org/wiki/Firewall_(physics)">black holes</a>.</p>
</div>
<div>
<p>He used this as motivation to study a “Artificial Agent” (or in standard lingo, <em>Reinforcement learning</em>) in the quantum setting:</p>
</div>
<div>
<p><img src="/images/agent-env-qc.png" width="600" /></p>
</div>
<div>
<p>His observation is: What is quantum? There are four options:</p>
</div>
<div>
<ul>
<li><div>
<em>CC</em>: Classical Agent, Classical Environment
</div></li>
<li><div>
<em>CQ</em>: Classical Agent, Quantum Environment
</div></li>
<li><div>
<em>QC</em>: Quantum Agent, Classical Environment
</div></li>
<li><div>
<em>QQ</em>: Quantum Agent, Quantum Environment
</div></li>
</ul>
</div>
<div>
<p>He noted that in the Quantum-Quantum setting, there are some foundational open problems:</p>
</div>
<div>
<ul>
<li><div>
How do you measure that you’re learning?
</div></li>
<li><div>
What does it mean to “act” in a fully quantum setting?
</div></li>
<li><div>
What role does decoherence play?
</div></li>
</ul>
</div>
<div>
<p>I don’t think even these questions are quite clear to me, let alone the answers; but still interesting to think about.</p>
</div>
<div>
<p>One idea/question I had is: What is the simplest truly quantum reinforcement learning problem?</p>
</div>
<div>
<h3 id="quantum-algorithms-for-the-hopfield-network-quantum-gradient-descent-and-monte-carlo">Quantum algorithms for the Hopfield network, quantum gradient descent, and Monte Carlo</h3>
</div>
<div>
<p><em>by Patrick Rebentrost</em></p>
</div>
<div>
<p>Next up was Patrick, who gave a far-reaching talk on a variety of topics that he and his colleagues have been researching over the last few years.</p>
</div>
<div>
<p>He started off by reminding us of a bunch of challenges that he posed in a prior paper:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
The “input” challenge - How to get data in to a quantum network? It turns out this is very subtle.
</div></li>
<li><div>
The “costing” challenge - Just how many qubits are required to implement these algorithms? How practical is it to build?
</div></li>
<li><div>
The “output” challenge - Even if we build an efficient quantum machine learning algorithm that produces a final state that encodes the answer; how do we read out the answer efficiently? It takes many measurements to extract the known state, so is it efficient to do so?
</div></li>
<li><div>
The “benchmarking” challenge - <em>even if</em> we solve all the above, how does it compare to classical algorithms? It can be very hard to prove that the quantum algorithm is better than any possible classical one.
</div></li>
</ol>
</div>
<div>
<p>Next, he talked about a quantum algorithm for training a so-called “Hopfield” neural network via the Hebbian learning procedure.</p>
</div>
<div>
<p>The Hopfield network is simply one in each every node is connected to every other node; and there is only one layer, and every node is both input and output (there are no layers, essentially). This may seem odd, and you should rightly wonder how you could train such a thing. One way to train it turns out to be the so-called “Hebbian” learning, which is inspired by the Human brain. The idea is captured by the phrase: “Neurons that fire together wire together”. With this idea in hand, it’s possible to develop a scheme to encode all this into a quantum computer, and perform all the updates and training. You can find more <a href="https://arxiv.org/pdf/1710.03599.pdf">here</a>.</p>
</div>
<div>
<p>For the everyday deep learning person, these ideas may sound a bit odd. Rightly so, because it’s not standard practice. Essentially the only reason to focus on these for in the quantum machine learning setting is that this is a network for which we <em>can</em> come up with a scheme to implement it on a quantum computer. A natural question is: Can we adapt the Hopefield-network techniques to work with multiple layers? I tentatively feel like the answer could be “yes”, but I haven’t thought a lot about it.</p>
</div>
<div>
<p>The next paper he talked about is this one: <a href="https://scirate.com/arxiv/1612.01789">Quantum gradient descent and Newton’s method for constrained polynomial optimization</a>.</p>
</div>
<div>
<p>I happened to read this one when it came out, because it was quite a big step. Previously, we had no idea how to even compute a quantum gradient, so this contribution was huge.</p>
</div>
<div>
<p>Unfortunately, the main problem of this paper is that the algorithm gets exponentially slower as the number of training steps increases. This is, at least naively, incredibly problematic for typical machine learning, where the number of steps is in the hundreds of thousands. In the paper they make the argument that oftentimes good results can be achieved after a very small number of steps, but it’s not clear to me how practical this is.</p>
</div>
<div>
<p>His final topic was <a href="https://scirate.com/arxiv/1805.00109">Quantum computational finance</a>; he was basically out of time, so didn’t go in to much detail, but the main idea is that again, using a standard technique in quantum computing called “amplitude amplification”, one can achieve a quadratic speedup in a certain kind of derivative-pricing. It turns out that banks and genuinely interested in these techniques, because being able to price something in say ~2 days, instead of 7 days, is a significant advantage market-wise.</p>
</div>
<div>
<p>Partick ended with a funny remark along these lines, which is that, the beauty of working in the finance world is that you don’t need to <em>prove</em> anything, you just simply build it, and let it go around making trades in the market; if it doesn’t work, you simply lose money!</p>
</div>
<div>
<h2 id="lunch">Lunch</h2>
</div>
<div>
<p>Over lunch, I had a really nice chat with <a href="https://github.com/pooya-git">Pooya Ronagh</a> from <a href="https://1qbit.com/">1Qbit</a> and <a href="https://homepages.cwi.nl/~rdewolf/">Ronald de Wolf</a>. We chatted largely about how the practical every-day machine learning could be aided by quantum techniques. Ronald pushed hard to understand what areas quantum researchers should focus on, and Pooya and I were trying to come up with ideas. Pooya had an interesting comment that, in many ways, faster machine learning isn’t super useful, because for the physical cost of a quantum computer, you can already buy significant hardware and get great results. So bad results faster doesn’t really help, in a foundational way.</p>
</div>
<div>
<p>Some thoughts we had is that maybe just flat-out alternatives to gradient descent would be interesting; i.e. we know there are areas where gradient-descent style optimisation is not great: <a href="http://silky.github.io/posts/2018-06-16-when-will-google-translate-be-great.html">translation</a>, program synthesis, neural architecture search, etc.</p>
</div>
<div>
<p>In any case, it was a very inspiring chat, and I was really glad to have met them!</p>
</div>
<div>
<h2 id="programmable-superpositions-with-hebbian-un-learning">Programmable Superpositions with Hebbian (un)-Learning</h2>
</div>
<div>
<p><em>by Wolfgang Lechner</em></p>
</div>
<div>
<p>This, I must say, was quite technical, and I didn’t quite follow most of it. But I did get the general idea.</p>
</div>
<div>
<p>The main tool of quantum machine learning is the so-called <a href="https://scirate.com/arxiv/0811.3171">HHL algorithm</a> (see also: <a href="https://scirate.com/arxiv/1802.08227">Quantum linear systems: a primer</a>). One thing it requires is efficient loading of the training data. It turns out that typically, if you want to load the training data into a quantum algorithm, in general you’ll need to do an exponential amount of work in the number of training samples. Which is hugely problematic. I think I need to understand this a bit more, but at least the basic idea was clear: the data-loading needs to be sped up.</p>
</div>
<div>
<p>The main contribution of this work is that, through a rather elaborate procedure, partially described here: <a href="https://arxiv.org/pdf/1708.02533.pdf">Programmable superpositions of Ising configurations</a> (but more in upcoming publications), it’s possible to prepare the required state by encoding it into a Hamiltonian, and then letting the Hamiltonian evolve via adiabatic evolution. How? Hebbian Learning, evidentally! I admit that I didn’t follow most of this talk, but I do think this kind of thing is quite interesting, and there’s definitely a need to solve this general, and reasonably embarassing problem.</p>
</div>
<div>
<hr />
</div>
<div>
<h2 id="day-2">Day 2</h2>
</div>
<div>
<p><img src="/images/innsbruck-2.jpg" width="800" /></p>
</div>
<div>
<p>We’re back. There first two talks were quite great, and there was another that was interesting and is worth a mention.</p>
</div>
<div>
<h3 id="opening-talk-artificial-intelligence-quantum-computing">Opening Talk: Artificial Intelligence &amp; Quantum Computing</h3>
</div>
<div>
<p>by Aske Plaat</p>
</div>
<div>
<p>Even though it had a reasonably uninspiring title, this talk was actually excellent, and should’ve, in fact, been the opening talk of the conference.</p>
</div>
<div>
<p>Aske introduced some motivation, and introduced some simplifying assumptions about AI to try and cut off typical arguments about what it means to be “intelligent”. He defined his working notion, which is “to <em>be</em> intelligent is to <em>act</em> intelligently”, which later was quite controversial to a number of people.</p>
</div>
<div>
<p>He had a unifying way of explaining why we’ve seen such a boom of AI recently, which is:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
Algorithms
</div></li>
<li><div>
Data
</div></li>
<li><div>
Speed
</div></li>
</ol>
</div>
<div>
<p>I think this is a nice way of phrasing it. He then dove into the various parts in more detail, starting with <em>algorithms</em>.</p>
</div>
<div>
<p>He introduced what he sees as two main camps of machine learning:</p>
</div>
<div>
<ul>
<li><div>
Connectionist AI, and,
</div></li>
<li><div>
Symbolic AI.
</div></li>
</ul>
</div>
<div>
<p>Connectionist AI, as he sees it, is the kind that we all know and love: Deep learning, neural networks, “bottom-up” reasoning, function approximation, etc.</p>
</div>
<div>
<p>Symbolic AI, as he sees it, is more related to philosophy, logics, ontologies, expert systems, planning, Q-Learning, and other kind of pre-defined “slow-thinking/high-level reasoning” ideas.</p>
</div>
<div>
<p>The main point he makes with the distinction is that maybe more merging between the two schools of thought needs to take place. He gives the example of AlphaGo as being a case where the two ideas merged. Another one I thought of is the idea of <a href="https://scirate.com/arxiv/1803.05252">Algebraic Machine Learning</a> which certainly has some grand claims, but is at least mildly interesting for it’s ideas.</p>
</div>
<div>
<p>He then made some comments about how speed is also relevant, and without it we wouldn’t see such a boom. Again this is of interest to quantum-computing types, because being faster than classical computers is fundamentally what the field is all about, and that’s where there’s been a lot of focus recently (i.e. quantum speedups over classical algorithms).</p>
</div>
<div>
<p>Aske also noted the abundance of benchmarks for classical machine learning, which became a theme for a few of the questions during question time. In particular we discussed who, if anyone, and how, if possible, to come up with some good benchmark datasets and problems for quantum machine learning. Presently, no-one has anything good along those lines.</p>
</div>
<div>
<p>He then noted some challenges in classical ML, and made the observation that <em>simply</em> achieving a speedup won’t solve these problems (for example, the adversial attacks, or the delayed credit assignment problem). The claim is that we need to put some effort into what truly <em>quantum</em> algorithms might look like.</p>
</div>
<div>
<p>The main thing I got out of the talk was the idea that we should be thinking about making new benchmarks for quantum machine learning.</p>
</div>
<div>
<h3 id="quantum-assisted-machine-learnnig-in-near-term-quantum-devices">Quantum-Assisted Machine Learnnig in Near-Term Quantum Devices</h3>
</div>
<div>
<p>by Alejandro Perdomo-Ortiz</p>
</div>
<div>
<p>Alejandro is very experienced in this field, it turns out. He’s been leading a team at NASA working on QML for the last 5 years, and now has moved to Rigetti, where he’s conducting research on the frontiers of quantum machine learning (also, Rigetti has a <a href="https://www.rigetti.com/qcs">quantum cloud service</a> coming …)</p>
</div>
<div>
<p>At NASA his drive was to drive interest in the practical usage of the quantum devices that NASA had purchased (in particular the D-Wave).</p>
</div>
<div>
<p>He noted that quantum chemistry, and the simulation of quantum systems, was the most natural idea, and everyone should be looking at it. But furthermore, he was tasked with thinking of other problems that could be mapped to these particular optimisation devices. Naturally, one idea is just straightforwad discrete optimisation; finding some satisfying assignment of variables for the minimisation of some particular cost function. And he conducted some early work here mapping protein folding to a certain kind of optimisation problem.</p>
</div>
<div>
<p>He echo’d Aske’s thoughts and said that we should be focusing on designing new algorithms, over just simply speed.</p>
</div>
<div>
<p>One of the most memorably quotes from his talk was “Look for the intractable, the more intractable the better, for me”.</p>
</div>
<div>
<p>One thing he spent a bit of time on was using the D-Wave to again implement one of these Hopfield networks (he called it here a “fully-visible model”), on a simplified digit dataset. Turned out it worked! Which essentially demonstrated that it was indeed possible to map a ML problem onto the device, and then have the device learn it’s own weights (couplings, here) which would allow it to do well at generating new digits!</p>
</div>
<div>
<p>Following this work, they then observed that infact they could train an autoencoder entirely classically, and then use the embedding vectors for all the training data as-in the setup above to <a href="https://arxiv.org/pdf/1801.07686.pdf">train a kind of hybrid generative</a> system:</p>
</div>
<div>
<p><img src="/images/auto-enc-qc-classical.png" /></p>
</div>
<div>
<p>I must say that I found this both interesting and confusing. It’s interesting because it’s a great way to use the complicated device to do “real” work, even when it has alone a very small amount of input nodes (it was something like 46, here, for this device). But it’s also confusing because most of the “juice” in the network is in the classical weights, not in the embedding vector itself. When I asked Alejandro about this, he said that it was mainly a way to demonstrate the hybrid set up, and that over time the idea is to make more regions quantum, and see how that changes things. I find it <em>very</em> interesting to think about how one would even go about jointly training a hybrid quantum-classical system.</p>
</div>
<div>
<p>The next idea he covered was the <a href="https://arxiv.org/pdf/1803.00745.pdf">learning of quantum circuits</a> see also <a href="https://arxiv.org/pdf/1804.04168.pdf">Differentiable Learning of Quantum Circuit Born Machine</a>.</p>
</div>
<div>
<p>This I think is a particularly great idea, and his approach was to focus on generate certain kinds of entangled states, with great results. They managed to find a state that has more entanglement, compared to the standard one, with this scheme. They also made some interesting observations about the expressive power of the depth of the circuits and what kind of states they can possible prepare.</p>
</div>
<div>
<p>His final insights were:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
Focus on the hardest problems of interest to ML exports, as this will be the quickest path to demonstrating a quantum advantage in the near-term.
</div></li>
<li><div>
Focus on novel hybrid quantum-classical approaches.
</div></li>
</ol>
</div>
<div>
<h3 id="lunch-1">Lunch</h3>
</div>
<div>
<p>For lunch, Gala and I decided to enjoy the beautiful park right next to the venue! By chance, there was a beer garden inside!</p>
</div>
<div>
<h3 id="machine-learning-for-designing-new-quantum-experiments">Machine learning for designing new quantum experiments</h3>
</div>
<div>
<p>by Alexey Melnikov</p>
</div>
<div>
<p>This talk was essentially another kind of program-synthesis problem, but this time in the language of optical elements. The idea is that, given some set of optical elements, and some number of qubits, how can we find all the possible sets of operations that make entangled states?</p>
</div>
<div>
<p>There new idea is to use a Reinforcement-Learning-inspired framework called “<a href="http://projectivesimulation.org">Projective Simulation</a>”. I must say that I found the framework a little odd, but they did get good results, and it’s available as a python library for you to experiment with!</p>
</div>
<div>
<h3 id="the-quantum-way-of-doing-computations-new-technologies-for-the-quantum-age">The Quantum Way of Doing Computations: New Technologies for the Quantum Age</h3>
</div>
<div>
<p>by Rainer Blatt</p>
</div>
<div>
<p>This talk was a bit oddly-placed. It was an overview of how quantum computing works, and an introduction to the trapped-ion style of quantum computing.</p>
</div>
<div>
<h3 id="panel">Panel</h3>
</div>
<div>
<p>The last event of the day was a very large panel of most of the speakers (~10 people) with a bunch of questions prepared by the organisers that were aimed to be thought-provoking. The best comment that came out of the entire discussion was from Matthias Troyer:</p>
</div>
<div>
<p>“That’s how you get a quantum advantage with zero qubits”</p>
</div>
<div>
<p>He was describing the recent work by Ewin Tang: <a href="https://scirate.com/arxiv/1807.04271">A quantum-inspired classical algorithm for recommendation systems</a> (which we actually already covered <a href="http://silverpond.com.au/2018/07/22/interesting-reads-in-quantum-computing-machine-learning-and-ethics.html">here</a>).</p>
</div>
<div>
<h3 id="open-areas-of-investigation">Open areas of investigation</h3>
</div>
<div>
<p>Here’s the list of open/interesting topics from today:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
Quantum datasets; benchmark problems,
</div></li>
</ol>
</div>
<div>
<ul>
<li><div>
Detecting entanglement?
</div></li>
<li><div>
Creation of states?
</div></li>
<li><div>
Classifying entangled vs. non-entangled?
</div></li>
<li><div>
How to generalise across qubit sizes?
</div></li>
<li><div>
Reinforcement learning problems? Quantum games? Quantum chess? Communication games?
</div></li>
</ul>
</div>
<div>
<ol start="2" style="list-style-type: decimal">
<li><div>
<p>What does truly quantum ML look like? Let’s stop trying to map classical algorithms to quantum ones, and just make up new ones</p>
</div></li>
<li><div>
This hybrid idea of linking parts of a network to qubits and parts being classical
</div></li>
</ol>
</div>
<div>
<ul>
<li><div>
How do you train these things?
</div></li>
</ul>
</div>
<div>
<ol start="4" style="list-style-type: decimal">
<li><div>
Near-term, if we want to do quantum ML, we should focus on what actual hardware will be used, and target our approaches to those models.
</div></li>
</ol>
</div>
<div>
<hr />
</div>
<div>
<h2 id="day-3">Day 3</h2>
</div>
<div>
<p><img src="/images/innsbruck-day-3.png" width="800" /></p>
</div>
<div>
<p>Today, there were only 3 talks; and we had a free afternoon! So we climbed* the big mountain!</p>
</div>
<div>
<p>*: Okay okay, by “climbed” I mean “took the lifts”. But there were 3 lifts!</p>
</div>
<div>
<h3 id="opening-talk-learning-from-quantum-data-strengths-and-weaknesses">Opening Talk: Learning from Quantum Data: Strengths and Weaknesses</h3>
</div>
<div>
<p>by Ronald de Wolf</p>
</div>
<div>
<p>This was a great and classic talk in the same vein as many talks in the theory of quantum computation.</p>
</div>
<div>
<p>Ronald addressed the natural problem of what you could do if you your data was given you to as a quantum state (thereby ignoring all the problems that have been brought up with QRAM in the past few days; let’s just suppose we have the state!).</p>
</div>
<div>
<p>The proposal is to consider supervised learning in a very formal sense; imagine we have a function: <span class="math inline"><em>f</em> : {0, 1}<sup><em>n</em></sup> → {0, 1}</span>.</p>
</div>
<div>
<p>Then, we can think of it as a supervised learning problem where we have <span class="math inline"><em>n</em></span> binary features, producing a single binary output, and we have our examples in the form: <span class="math inline">(<em>x</em>, <em>f</em>(<em>x</em>))</span>.</p>
</div>
<div>
<p>Ronald wanted us to consider the so-called <em>sample</em> complexity, i.e. how many times do we have to evaluate <span class="math inline"><em>f</em></span>, instead of the more standard <span class="math inline"><em>t</em><em>i</em><em>m</em><em>e</em></span> complexity. In this sense here, the ideas are at least related, because fewer samples will take less time.</p>
</div>
<div>
<p>In general we’d need <span class="math inline">2<sup><em>n</em></sup></span> examples to learn <span class="math inline"><em>f</em></span> fully, but we’ll want to do <em>efficient</em> learning, so we’d like to learn from far fewer queries than that.</p>
</div>
<div>
<p>Ronald preferred to work in the framework of PAC-learnability, which was introduced by Leslie Valiant in 1984. Leslie has a nice readable book on the topic (I’ve unfortunately lost my copy a while ago) which is well worth a read.</p>
</div>
<div>
<p>It turns out that in 1995, Bshouty and Jackson introduced a <a href="http://www.mathcs.duq.edu/~jackson/quantex.pdf">quantum version of this notion</a> (see also <a href="https://arxiv.org/pdf/quant-ph/0202066.pdf">Quantum DNF Learnability Revisited</a>).</p>
</div>
<div>
<p>Their idea is to consider the state of training data: <br /><span class="math display">$$ \sum_{x \in \{0,1\}^n } \sqrt{D(x)} |x, f(x)\rangle $$</span><br /> To demonstrate a speedup, suppose that we have the uniform distribution over the samples; so then our state becomes <br /><span class="math display">$$ \frac{1}{2^n} \sum_{x \in \{0,1\}^n } |x, f(x)\rangle $$</span><br /> The main idea is to hit this with the Fourier sampling tool, that is a classic trick in quantum algorithms. The essential idea is, firstly support that <span class="math inline">(<em>x</em>)= ± 1</span>, then we can do another standard trick, the Hadamard transformation, and obtain the state <br /><span class="math display">$$ \frac{1}{2^n} \sum_{x \in \{0,1\}^n } \hat{f}(s)|s\rangle $$</span><br /></p>
</div>
<div>
<p>where <br /><span class="math display">$$\hat{f}(s) = \frac{1}{2^n} \sum_{x} f(x) (-1)^{s \cdot x}$$</span><br />.</p>
</div>
<div>
<p>The point here is that when you measure this final state, the state you see is <span class="math inline"><em>s</em></span> with probability <span class="math inline">$\hat{f}(s)^2$</span>. For a certain choice of <span class="math inline"><em>f</em></span>, namely when <span class="math inline"><em>f</em></span> is linear mod 2, then you can learn the function perfectly in exactly one query. Classically you would require at least <span class="math inline"><em>n</em></span> queries. Great reduction!</p>
</div>
<div>
<p>He then went into a few more examples, getting a little bit more technical each time; one was for the so-called “Coupon collector” problem, which is simply: imagine you get a random baseball card from a store, how many times do you need to visit the store before you have the entire set of cards?</p>
</div>
<div>
<p>Again, because this is a uniform problem, we can use similar techniques to improve on it. Classical, one can find that the expected number of store visits (samples) is approximately <span class="math inline"><em>N</em>log <em>N</em></span> (where <span class="math inline"><em>N</em></span> is the number of cards in total), but quantumly it can be done with <span class="math inline"><em>O</em>(<em>N</em>)</span> samples.</p>
</div>
<div>
<p>Perhaps of interest, was some conclusions that they were able to show that <em>no</em> quantum speedup can be obtained when for <em>all</em> distributions; i.e. there are some bad distributions that we will just struggle with. I don’t think anyone finds this particularly surprising, and shouldn’t have a big impact on real-world problems, because typically, most data isn’t, shall we say, adversially prepared; the distributions tend to be wildly different (a natural example being the set of all images of mountains as a subset of all possible images).</p>
</div>
<div>
<p>The main idea here is that by utilising standard tricks from quantum algorithms we can get significant speedups when we know something about the distribution that we are learning from.</p>
</div>
<div>
<h3 id="limitations-on-learning-of-quantum-processes">Limitations on learning of quantum processes</h3>
</div>
<div>
<p>by Mario Ziman</p>
</div>
<div>
<p>This one was a little bit technical, but it had some interesting ideas.</p>
</div>
<div>
<p>Mario phrased the problem of quantum machine learning as follows:</p>
</div>
<div>
<p><img src="/images/mario-qml.png" /></p>
</div>
<div>
<p>The point being that in typical ML we want to modify the function <span class="math inline"><em>f</em></span>, and in quantum ML then we wish to modify the unitary <span class="math inline"><em>U</em><sub><em>f</em></sub></span>. This turns out to be quite problematic, because this function is truly quantum, and we know that quantum states suffer from the no-cloning principle: you cannot copy an unknown quantum state; so you can only use it once. Mario mentioned that this results in a <em>No-programming</em> theorem, which means that we cannot perfectly store an unknown quantum transformation (i.e., <em>even if</em> we find a <span class="math inline"><em>U</em><sub><em>f</em></sub></span> that works well; we can’t save it! We have to know how many times we want to use it <em>in advance!</em>).</p>
</div>
<div>
<p>However, it turns out we can still make some progress by, instead of requiring some kind of exact copy, we aim for probabilistic performance. The only remaining thing I got from this talk was that probabilistic learning, in their sense involving some kind of “probabilistic Q learning” is related to quantum teleportation. You can read about this work more <a href="https://scirate.com/arxiv/1809.04552">here</a>.</p>
</div>
<div>
<h3 id="discovering-physical-concepts-with-neural-networks">Discovering physical concepts with neural networks</h3>
</div>
<div>
<p>by Renato Renner</p>
</div>
<div>
<p>This was a talk I was quite excited about. The paper for it is <a href="https://scirate.com/arxiv/1807.10300">here</a>. They’ve also made <a href="https://github.com/eth-nn-physics/nn_physical_concepts">the code available</a>, in TensorFlow.</p>
</div>
<div>
<p>The fundamental idea is really nice: Maybe we can build a neural network to act exactly as a standard human physicist would: they shall observe data, try and form theories, ask questions of their theories, and then check the answers.</p>
</div>
<div>
<p>This is very nicely expressed by the picture from the paper:</p>
</div>
<div>
<p><img src="/images/physical-concepts.png" width="800" /></p>
</div>
<div>
<p>The point is that they train an autoencoder on the data, but the put constraints on the latent vector so that the entries by adding the mutual information between them on to the loss so-as to require independence; i.e. the parameters that the network learns should be independent.</p>
</div>
<div>
<p>They then introduce this idea of questions and answers. Unfortunately, I think the way this idea doesn’t go far enough is by, it seems to me, treating the answers as the input data itself; so that truly this network only functions as a special kind of autoencoder (at least, this is how it is in the code, and as far as I can see in the paper).</p>
</div>
<div>
<p>In any case, they’re able to show several problems where it is able to look at experimental data and where the latent variables are correlated to the terms that they expected to see in the equations that model these phenomena. I think that’s pretty cool.</p>
</div>
<div>
<p>One thing Renato noted quite strongly was that perhaps this isn’t super surprising, and maybe the network received a lot of help by the way the data was sent to it. I think that this could be mitigated, maybe, by thinking a bit more about the quesiton/answer set up, and more generally thinking about how we can allow the network to reject data samples.</p>
</div>
<div>
<p>Some ideas I had during this talk related to the kind of “falsifiability” ideas; namely that if this system is forced to come up with theories for data, then how can we also ensure that the theories it has can be proven wrong?</p>
</div>
<div>
<p>My other idea was, what if instead of just having a latent variable, i..e an independent variable, have an entire neural network in there, that could perhaps serve as an “independent explanation”.</p>
</div>
<div>
<p>Overall, I quite enjoyed this talk and idea.</p>
</div>
<div>
<h3 id="open-areas-of-investigation-1">Open areas of investigation</h3>
</div>
<div>
<p>The interesting things that came to me regarding today were:</p>
</div>
<div>
<ul>
<li><div>
What other cool quantum algorithm tricks should we be using?
</div>
<div>
<ul>
<li><div>
Bomb testing?
</div></li>
<li><div>
The bomb-testing thing is a kind of learning anyway. Probably interesting?
</div></li>
</ul>
</div></li>
<li><div>
If we do really want to learn truly quantum unitaries, then what’s the deal with having to know how many times we want to use it!? That’s crazy!
</div></li>
<li><div>
How can we make a better machine for generating theories?
</div></li>
</ul>
</div>
<div>
<hr />
</div>
<div>
<h2 id="day-4">Day 4</h2>
</div>
<div>
<p><img src="/images/innsbruck-day-4.png" width="800" /></p>
</div>
<div>
<p>Well, it’s Thursday night, and I’ve just finished up my last day at the conference. Tomorrow, we’ll be heading on our (short) holiday! While QML+ formally has two more talks tomrorrow, they are less relevant to me personally, plus we need to get a head start to make it to some waterfalls!</p>
</div>
<div>
<p>Here’s my summary of the talks I attended today!</p>
</div>
<div>
<h3 id="opening-talk-mlq">Opening Talk: ML+Q</h3>
</div>
<div>
<p>by Matthias Troyer</p>
</div>
<div>
<p>With an amusingly-titled talk, Matthias is the master of classical simulation algorithms for quantum processes. He spends most of his time working on the software side, trying to demonstrate practical quantum speedups for optimisation problems.</p>
</div>
<div>
<p>As with most of the other talks, he described several pieces of work. The first was a <a href="https://arxiv.org/pdf/1606.02318.pdf">neural network that could be used to learn a quantum wave function</a>, and then used to find phases and amplitudes of given states, and compute other properties.</p>
</div>
<div>
<p>Their setup was the (seemingly-standard) Restricted Boltzmann Machine, where the input was whether-or-not there is a z-rotation on the given qubit, and the output being the inner product with some state <span class="math inline">|<em>s</em>⟩</span>.</p>
</div>
<div>
<p><img src="/images/nqs.png" /></p>
</div>
<div>
<p>But, non-standardly, the weights of this network are actually found using what they refer to as “reinforcement learning”, but is actually something called “<a href="https://scirate.com/arxiv/cond-mat/0702349">Stochastic Reconfiguration</a>”. Once they find initial values for the weights, by looking at the Hamiltonian of the particular system, they then fine-tuned, if they want to compute properties that depend on time. It’s a little bit involved, to say the least.</p>
</div>
<div>
<p>Anyway, having done this, they do acheieve some nice results. They are able to use their neural network to compute various properties quite well.</p>
</div>
<div>
<p>Later, they applied an RBM again, but without the weird “Stochastic Reconfiguration”, and were able to get very good results in <a href="https://scirate.com/arxiv/1703.05334">learning quantum states</a>.</p>
</div>
<div>
<p>He then spent a bit of time covering his work on <a href="https://scirate.com/arxiv/1806.06081">quantum annealing</a>. In particular, in that worked they observe that quantum annealers seem to be fated to always produce unfair samples of the potential states; i.e. not every state has equal probability to appear. Ingeniously, they came up with a classical simulation of quantum annealing that is actually faster and more accurate. Even more ingeniously, they show that infact they can implement the classical simulation as a quantum process, and <em>again</em> get a speedup, for a total of a quartic (2 times quadratic) speedup!</p>
</div>
<div>
<p>All this resulted in the numerical comment that if there is any quantum annealing problem you’re running classically for more than 1 day, you’ll go faster if you use a quantum annealer.</p>
</div>
<div>
<p>One of the interesting conclusions for this part of the work was, when you’re simulating adiabatically evolving something classically, sometimes it’s better, if you want tunneling, to evolve very fast (<a href="https://en.wikipedia.org/wiki/Adiabatic_theorem">the adiabatic theorem</a> would tell us we need to evolve slowly). He demonstrated this in an amusing way by saying that he could tunnel through the wall in room if we would just close our eyes for 30 seconds, instead of 30 microseconds.</p>
</div>
<div>
<p>His other summaries were:</p>
</div>
<div>
<ul>
<li><div>
Neural nets are great for learning efficient representations of wave functions; and probably more
</div></li>
<li><div>
Stoquastic quantum annealing can be well mimicked by a classical laptop
</div></li>
<li><div>
Sampling bias makes quantum annealers bad for this task
</div></li>
<li><div>
Gate-model quantum computers <em>will</em> accelerate quantum-inspired algorithms
</div></li>
</ul>
</div>
<div>
<h3 id="early-lunchhike">Early Lunch/Hike</h3>
</div>
<div>
<p>Unfortunately, a talk I was looking forward to, by Franceso Petruccione, probably related to <a href="https://scirate.com/arxiv/1704.02146">this work</a> was cancalled, so Gala and I went for a long hike instead. We almost got lost, found beautiful forests, found a beautiful field that reminded me of Jurassic Park, lost faith in ever seeing the bottom of the mountain again and eventually made it back to the lifts alive.</p>
</div>
<div>
<p>This impromptu adventure meant we just got back in time for the last talk of the day.</p>
</div>
<div>
<h3 id="quantum-speedup-in-testing-causal-hypotheses">Quantum speedup in testing causal hypotheses</h3>
</div>
<div>
<p>by Giulio Chiribella</p>
</div>
<div>
<p>This talk was essentially based around <a href="https://arxiv.org/pdf/1806.06459.pdf">this paper</a>.</p>
</div>
<div>
<p>The main point is to think about a framework for causal hypotheses, and then see how classical and quantum approaches compare. The setup as like so:</p>
</div>
<div>
<p><img src="/images/causal.png" /></p>
</div>
<div>
<p>We think of curly-C as some kind of unknown process (for example, <code>node.js</code>, ha ha ha), and then ask ourselves: What is the causal relationship between B and A? And between C and A?</p>
</div>
<div>
<p>The setting Giulio proposes is that we want to be able to determine exactly, from a given set of hypotheses, which one is correct. Here, imagine the following:</p>
</div>
<div>
<ul>
<li><div>
<strong>Hypothesis 1</strong>: B is dependent on A, and C is uniformly random.
</div></li>
<li><div>
<strong>Hypothesis 2</strong>: C is dependent on A, and B is uniformly random.
</div></li>
</ul>
</div>
<div>
<p>The question is: Who can do better, as a function of the number of trials, to determine which hypothesis is right? In order to be able to make progress, we allow ourselves <em>interventions</em>; i.e. that we can feed data into <span class="math inline"><em>A</em></span>, and then use that to make subsequent queries to curly-C.</p>
</div>
<div>
<p>For reasons I don’t really understand, in the paper they claim that classically, if the dimension of all variables is finite and fixed to <span class="math inline"><em>d</em></span>, then, if B (or C) is dependent on A, then that means that the function mapping A to B is invertible. With such a constraint, it’s easy to see that it’s possible to determine the difference between the two hypothesis. The value of interest to them is the “discrimination rate”, as the number of experiments is performed. They find that it is <span class="math inline">log <em>d</em></span>. Quantumly, they find that they are able to differentiate the two hypothesis with discriminatio rate <span class="math inline">2log <em>d</em></span>. This, in the theory they’ve developed, is exponentially better than the classical case. Great!</p>
</div>
<div>
<p>I left this talk a little bit confused, but at least vaugely interested in the idea of quantum causal modelling.</p>
</div>
<div>
<h3 id="open-areas-of-investigation-2">Open areas of investigation</h3>
</div>
<div>
<p>The interesting things that came to me regarding today were:</p>
</div>
<div>
<ul>
<li><div>
How to combine SciNet with the neural-nets for determining wave functions?
</div></li>
<li><div>
What’s the relationship between tensor networks and these neural nets? and Conv nets?
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.01437">Duality of Graphical Models and Tensor Networks</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.04045">Neural-Network Quantum States, String-Bond States, and Chiral Topological States</a>
</div></li>
</ul>
</div>
<div>
<h3 id="final-thoughts-on-the-conference">Final thoughts on the conference</h3>
</div>
<div>
<p>Overall, I’m inspired by quantum machine learning. I feel like there’s heaps of cool things to do.</p>
</div>
<div>
<p>Unfortunately, I’m disappointed by some things about this conference. Having come from so far away, and wanting to maximise my time the best way, I found it frustrating that even the <em>titles</em> for most of the talks weren’t known in advance.</p>
</div>
<div>
<p>I found the conference events and overall feeling to be very non-inclusive. There was lots of mention of people working in ML/QC as “guys”; there were lots of in-crowds and, while there was lots of talk of wanting to mix with the “machine learning crowd”, people were somewhat skeptical of me not being associated with any university, and attempts to organise people as either “machine learning/classical” and “quantum”. Further, there was also no mention of a code of conduct.</p>
</div>
<div>
<p>Sarah Moran, of <a href="https://girlgeekacademy.com/">Girl Geek Academy</a> once gave a talk about “micro positive-actions” (or something, I can’t remember the name) but the ones that stuck out to me were:</p>
</div>
<div>
<ul>
<li><div>
Name tags, always (this conference did well at this),
</div></li>
<li><div>
Always leave a spot open in a talking circle,
</div></li>
</ul>
</div>
<div>
<p>These are great rules of thumb for any organisers to keep in mind. If you have more, please let me know!</p>
</div>
<div>
<p>Overall, it would be great to see these academic conferences put significant effort into making their conferences feel much more welcoming to all types of people.</p>
</div>
]]></summary>
</entry>
<entry>
    <title>How To Program</title>
    <link href="https://silky.github.io/posts/2018-08-03-how-to-program.html" />
    <id>https://silky.github.io/posts/2018-08-03-how-to-program.html</id>
    <published>2018-08-03T00:00:00Z</published>
    <updated>2018-08-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on August  3, 2018
    
        by Thich Nhat Hanh (aka Noon van der Silk)
    
</div>

<div>
<style type="text/css">
p {
  margin: 10px;
  padding: 50px;
  background: #eaeaea;
  text-align: center;
}

div { text-align: center; }

center { margin-top: 30px; margin-bottom: 30px; }
</style>
</div>
<div>
<p>The first thing to do is to stop whatever else you are doing.</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/how-to-program/blank.png" />
</div>
<div>
</center>
</div>
<div>
<p>Now stand or sit in a comfortable position. <br /><br />However you wish.</p>
</div>
<div>
<p>Notice your breathing.</p>
</div>
<div>
<p>As you breathe in, <br />be aware <br />that you are <br />breathing in. <br
/><br /> As you breathe out, <br />notice that you are <br />breathing out.</p>
</div>
<div>
<p><strong>Notes on Programming</strong><br /><br />Many of us spend a lot of time programming. We program at our jobs, we program at cafes, we program at home. To <em>program</em>, in this blog, means to program in such a way that you enjoy programming, to program in a relaxed way, with your mind awake, calm, and clear. This is what we call <em>programming</em>, and it takes some training and practice.</p>
</div>
]]></summary>
</entry>
<entry>
    <title>The Ethics of AI - An Empathy-Based Approach?</title>
    <link href="https://silky.github.io/posts/2018-07-25-ethics-of-AI.html" />
    <id>https://silky.github.io/posts/2018-07-25-ethics-of-AI.html</id>
    <published>2018-07-25T00:00:00Z</published>
    <updated>2018-07-25T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on July 25, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>There’s lots of talk about the Ethics of AI at the moment. As with any research, there’s too much for any one person to read. Here’s a bunch of papers that I’ve collected haphazardly in the early part of this year:</p>
</div>
<div>
<ul>
<li><div>
<a href="https://scirate.com/arxiv/1711.03846">“Dave…I can assure you…that it’s going to be all right…” – A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1709.06692">A Voting-Based System for Ethical Decision Making</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1511.06578">Actually, It’s About Ethics in Computational Social Science: A Multi-party Risk-Benefit Framework for Online Community Research</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07373">Attentive Explanations: Justifying Decisions and Pointing to the Evidence (Extended Abstract)</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1502.05838">Automated Reasoning for Robot Ethics</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1702.00137">Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.06881">Children and the Data Cycle: Rights and Ethics in a Big Data World</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1606.06565">Concrete Problems in AI Safety</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07076">Does mitigating ML’s impact disparity require treatment disparity?</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1706.03021">Ethical Artificial Intelligence - An Open Question</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1701.07769">Ethical Considerations in Artificial Intelligence Courses</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1707.05259">Ethics of autonomous information systems towards an artificial thinking</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1504.05603">Formalizing Preference Utilitarianism in Physical World Models</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1703.06354">Goal Conflict in Designing an Autonomous Artificial System</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1610.03229">In The Wild Residual Data Research and Privacy</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1709.05929">Institutionally Distributed Deep Learning Networks</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.05791">Maintaining The Humanity of Our Models</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1607.08289">Mammalian Value Systems</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.06882">Mapping for accessibility: A case study of ethics in data science for social good</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07111">Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.06664">Predict Responsibly: Increasing Fairness by Learning To Defer</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1609.03266">Recovering the History of Informed Consent for Data Science and Internet Industry Research Ethics</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1706.02513">Responsible Autonomy</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1701.02388">Stoic Ethics for Artificial Agents</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1606.02583">The Dark Side of Ethical Robots</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.00561">This robot stinks! Differences between perceived mistreatment of robot and computer partners</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1703.04741">Towards Moral Autonomous Systems</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.05905">Using experimental game theory to transit human values to ethical AI</a>
</div></li>
</ul>
</div>
<div>
<p>One thing I wanted to think about is, speaking as someone working in this field and interested in making changes in my day-to-day life, what kind of tools or ideas would be useful for me? What should I do?</p>
</div>
<div>
<p>Alongside this thought, another thought I had is that somehow the big lists of rules feel very impersonal and disconnected from my experiences. I also feel a little bit unsatisfied about opt-in rules. Here’s a few from the around the place, that I’ve seen:</p>
</div>
<div>
<ul>
<li><div>
<a href="https://futureoflife.org/ai-principles/">Future of Life</a> (June 2018, relevant items)
</div>
<div>
<ul>
<li><div>
5 - Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.
</div></li>
<li><div>
6 - Safety: AI systems should be safe and secure throughout their operational lifetime, and verifably so where applicable and feasible
</div></li>
<li><div>
7 - Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.
</div></li>
<li><div>
8 - Judical Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.
</div></li>
<li><div>
9 - Responsibility: Designers and building of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.
</div></li>
<li><div>
10 - Value Alignment: Highly autonomous AI systems should be designed so that their goals and behviours
</div></li>
<li><div>
11 - Human Values: AI Systems should be designed and operated so as to be compatible with ideals of human dignift, rights, freedoms, and cultural diversity.
</div></li>
<li><div>
12 - Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.
</div></li>
<li><div>
13 - Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.
</div></li>
<li><div>
14 - Shared Benefit: AI technologies should benefit and empower as many people as possible.
</div></li>
<li><div>
15 - Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.
</div></li>
<li><div>
16 - Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human chose objectives.
</div></li>
<li><div>
17 - Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather an subvert, the social and civic processes on which the health of society depends.
</div></li>
<li><div>
18 - AI Arms Race: An arms race in lethal autonomous weapons should be avoided.
</div></li>
</ul>
</div></li>
<li><div>
<a href="https://www.aiforhumanity.fr/en/">AI For Humanity</a> (June 2018)
</div>
<div>
<ul>
<li><div>
01 - Develop an aggressive data policy
</div></li>
<li><div>
02 - Targeting four strategic sectors
</div></li>
<li><div>
03 - Boosting the potential of French research
</div></li>
<li><div>
04 - Planning for the impact of AI on labour
</div></li>
<li><div>
05 - Making AI more environmentally friendly
</div></li>
<li><div>
06 - Opening up the black boxes of AI
</div></li>
<li><div>
07 - Ensuring that AI supports inclusivity and diversity
</div></li>
</ul>
</div></li>
<li><div>
<a href="http://humansforai.com/">Humans for AI</a> (June 2018)
</div>
<div>
<ul>
<li><div>
Broaden the pipeline of minorities currently in tech careers, seeking to move to careers in AI by being the go to destination for all things AI because we believe that diversity of thought and opinion ultimately builds better products.
</div></li>
<li><div>
Open and inclusive community of people interested in AI by facilitating interactions with experts, practitioners and thought leaders in the field.
</div></li>
<li><div>
Leverage AI to release a set of free products built by this community to further our mission of bringing diversity to AI.
</div></li>
<li><div>
Demystify AI by providing a basic understanding of the concepts, thinking and events in AI for novices and non-technical people interested in how AI will impact their lives and their jobs.
</div></li>
</ul>
</div></li>
<li><div>
<a href="https://arxiv.org/pdf/1606.06565.pdf">Concrete Problems in AI Safety</a> (2016)
</div>
<div>
<ul>
<li><div>
Avoid Negative Side Effects
</div></li>
<li><div>
Avoid Reward Hacking
</div></li>
<li><div>
Scalable Oversight
</div></li>
<li><div>
Safe Exploration
</div></li>
<li><div>
Robustness to Distributional Shift
</div></li>
</ul>
</div></li>
</ul>
</div>
<div>
<p>I have a few problems with these rules:</p>
</div>
<div>
<ul>
<li><div>
It’s easy to imagine situations in which they are counter-productive,
</div></li>
<li><div>
I don’t feel a lot of ownership of them, as I wasn’t involved in their construction,
</div></li>
<li><div>
No-one is enforcing them on me,
</div></li>
<li><div>
They’re often highly impractical or contain colloquial/regional/policital concerns (“Boost French Research …”),
</div></li>
<li><div>
They’re also very overwhelming and demanding, how can I ensure that we do <em>all</em> of them?
</div></li>
<li><div>
Even if I <em>say</em> I’m doing these things, how does any non-technical person know? How can I prove it?
</div></li>
</ul>
</div>
<div>
<p>The positive aspects of them are:</p>
</div>
<div>
<ul>
<li><div>
It’s sometimes easy to think about how to apply them to day-to-day work,
</div></li>
<li><div>
They help me think of things that I might not care about day-to-day (i.e. the environmental concerns?),
</div></li>
<li><div>
It might help to lobby governments/organisations to get funding to make progress on certain aspects?
</div></li>
<li><div>
It provides a framework that might be useful for discussing with colleagues/other people
</div></li>
</ul>
</div>
<div>
<p>So, what should any given engineer working in this area do? One thought I’ve had recently is a simple one: Let’s just aim at building empathy for the people that will be affected by our software.</p>
</div>
<div>
<p>This is reasonably actionable, say, with local groups by organising meetings between technical people and the people that may be affected. I.e. in the medical-AI setting, let’s organise regular catch-ups between the engineers, the doctors, nursing staff, and hospital adminstration types, along with perhaps patient representatives.</p>
</div>
<div>
<p>In the setting, of, say, law software, again we just set up regular events for the two groups to chat through issues, work together on small projects, and build a mutual understanding of difficulties.</p>
</div>
<div>
<p>I think this approach is a bit nicer than, say, creating a new set of rules that make sense for us locally, and then forcing people to follow them. One idea I like about the empathy-based/collaborative approach (or “human-centered design”; another term for this kind thing), is that it allos people to <em>adapt to local circumstances</em>, which I think is really crucial in allowing any one person to feel like they have some control over the application of any rules they come up with, and thus getting them to actually take an interest in enforcing them in their organisation.</p>
</div>
<div>
<p>So, my new rule of thumb for this ethics-related AI stuff will be: Can I meet with some of the people that will be affected? What are their thoughts? What problems are they working through and what are they interested in?</p>
</div>
<div>
<p>As always, I’m interested in your thoughts on the matter!</p>
</div>
]]></summary>
</entry>
<entry>
    <title>Diagrams In Hakyll!</title>
    <link href="https://silky.github.io/posts/2018-06-23-Diagrams-In-Hakyll.html" />
    <id>https://silky.github.io/posts/2018-06-23-Diagrams-In-Hakyll.html</id>
    <published>2018-06-23T00:00:00Z</published>
    <updated>2018-06-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on June 23, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>I stumbled across this blogpost of <a href="http://www.corentindupont.info/blog/posts/Programming/2015-09-14-diagrams.html">Corentin Dupont</a> where he put together a library that allows you to modify your hakyll blog so that you can have inline diagrams! As anyone knows, this was amazingly exciting to me, because I love <a href="https://archives.haskell.org/projects.haskell.org/diagrams/"><code>diagrams</code></a>.</p>
</div>
<div>
<p>So I quickly tried to set it up; but, much to my sadness it didn’t immediately work.</p>
</div>
<div>
<p>Luckily, however, I was able to make it worked by hacking around in the two relevant repos:</p>
</div>
<div>
<ul>
<li><div>
<a href="https://github.com/silky/diagrams-pandoc">diagrams-pandoc</a>
</div></li>
<li><div>
<a href="https://github.com/silky/hakyll-diagrams">hakyll-diagrams</a>
</div></li>
</ul>
</div>
<div>
<p>The main result is a function, <code>pandocCompilerDiagrams</code>, that I included into my hakyll site file like so:</p>
</div>
<div>
<pre><code>match &quot;posts/*&quot; $ do
    route $ setExtension &quot;html&quot;
    compile $ 
            (pandocCompilerDiagrams &quot;images/diagrams&quot; &lt;|&gt; pandocMathCompiler)
        &gt;&gt;= loadAndApplyTemplate &quot;templates/post.html&quot;    postCtx
        &gt;&gt;= saveSnapshot &quot;content&quot;
        &gt;&gt;= loadAndApplyTemplate &quot;templates/default.html&quot; postCtx
        &gt;&gt;= relativizeUrls</code></pre>
</div>
<div>
<p>And so now, I can have inline diagrams! Check it out:</p>
</div>
<div>
<p>Imagine we had a circle:</p>
</div>
<div>
<img src="/images/diagrams/374a326c0114a031.png" />
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">example <span class="fu">=</span> circle <span class="dv">1</span></code></pre></div>
</div>
<div>
<p>But now, what if the circle was repeated 5 times</p>
</div>
<div>
<img src="/images/diagrams/08c4ef90376ce8a9.png" />
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">example <span class="fu">=</span> hcat (take <span class="dv">5</span> <span class="fu">$</span> repeat (circle <span class="dv">1</span>))</code></pre></div>
</div>
<div>
<p>Cool!</p>
</div>
<div>
<p>To celebrate, let’s draw the Sierpinksi triangle:</p>
</div>
<div>
<p>The basic building block:</p>
</div>
<div>
<img src="/images/diagrams/173ff52710458947.png" />
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sierp d <span class="fu">=</span> d <span class="fu">===</span> (d <span class="fu">|||</span> d) <span class="fu">#</span> centerXY
example <span class="fu">=</span> sierp (triangle <span class="dv">1</span>)</code></pre></div>
</div>
<div>
<p>Let’s go!</p>
</div>
<div>
<img src="/images/diagrams/ddbe64a73b5cee43.png" />
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell">sierp d <span class="fu">=</span> d <span class="fu">===</span> (d <span class="fu">|||</span> d) <span class="fu">#</span> centerXY
example <span class="fu">=</span> foldl (\d _ <span class="ot">-&gt;</span> sierp d) (triangle <span class="dv">1</span>) [<span class="dv">1</span><span class="fu">..</span><span class="dv">3</span>]</code></pre></div>
</div>
<div>
<p>Colours!</p>
</div>
<div>
<img src="/images/diagrams/3d45411fafd7d24c.png" />
<div class="sourceCode"><pre class="sourceCode haskell"><code class="sourceCode haskell"><span class="kw">import </span><span class="dt">Data.Colour.Palette.ColorSet</span>

color n <span class="fu">=</span> rybColor (n<span class="fu">*</span><span class="dv">2</span>)
 
sierp d n <span class="fu">=</span> d1 <span class="fu">===</span> (d2 <span class="fu">|||</span> d2) <span class="fu">#</span> centerX
    <span class="kw">where</span>
        d1 <span class="fu">=</span> d <span class="fu">#</span> bg (color n)
        d2 <span class="fu">=</span> d <span class="fu">#</span> bg (color (n<span class="fu">+</span><span class="dv">1</span>))

example <span class="fu">=</span> foldl step d0 [<span class="dv">0</span><span class="fu">..</span><span class="dv">5</span>]
    <span class="kw">where</span>
        d0       <span class="fu">=</span> triangle <span class="dv">1</span> <span class="fu">#</span> lw <span class="dv">0</span>
        step d n <span class="fu">=</span> sierp d (n<span class="fu">*</span><span class="dv">2</span>)</code></pre></div>
</div>
<div>
<p>Happy days!</p>
</div>
]]></summary>
</entry>
<entry>
    <title>When will Google Translate be great?</title>
    <link href="https://silky.github.io/posts/2018-06-16-when-will-google-translate-be-great.html" />
    <id>https://silky.github.io/posts/2018-06-16-when-will-google-translate-be-great.html</id>
    <published>2018-06-16T00:00:00Z</published>
    <updated>2018-06-16T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on June 16, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>I’ve been reading “<a href="https://www.amazon.com/Surfaces-Essences-Analogy-Fuel-Thinking/dp/0465018475/">Surfaces and Essences</a>” by Doug Hofstadter and Emmanuel Sander.</p>
</div>
<div>
<center>
</div>
<div>
<a href="https://www.amazon.com/Surfaces-Essences-Analogy-Fuel-Thinking/dp/0465018475/"><img src="/images/surfaces-and-essences.png" /></a>
</div>
<div>
</center>
</div>
<div>
<p>You can essentially judge this book by it’s cover: It argues that analogies are the key technique we use to think and understand. I quite love this book, in particular because it presents lots of interesting ideas for people interested in the topic, and for people interested in AI and machine learning.</p>
</div>
<div>
<p>The reason I enjoy this book so much is because I think it presents a very strong task for machine learning people to tackle; namely to build a system that is capable of this analogical reasoning. One thing that’s true of <strong>all</strong> modern machine learning systems it that their knowlege is very “narrow” and, almost all of the time, the bounds of it are determined entirely before training.</p>
</div>
<div>
<p>In any case, we’re focused right now on translation. Doug recently wrote about his thoughts here: <a href="https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/">The Shallowness of Google Translate</a>.</p>
</div>
<div>
<p>I’m not going to go into a lot of detail here; I just want to track the progress of a specific phrase that Doug and Emmanuel hvea in the book. They started tracking it in 2004, and it being 2018 now; 14 years later! I wanted to see how things had progressed.</p>
</div>
<div>
<p>Here’s the complex paragraph (in French) and the task is to translate it into English:</p>
</div>
<div>
<p><strong>Original</strong></p>
</div>
<div>
<blockquote>
<div>
<p>Parfois, le succès ne fut pas au rendez-vous. On a beau y penser très fort, le bon numéro ne sort pas forcément. Sagan prenait échecs d’auteur dramatique comme les revers casino, avec respect pour les caprices de la banque et du ciel. Il faut bien pedre un peu, pour mieux savourer la gagne du lendemain. Qui ne l’a pas vue « récupérer » en quelques quarts d’heure les pertes de toute une nuit ne peut comprendre comme c’est joyeux de narguer le sort.</p>
</div>
</blockquote>
</div>
<div>
<p><strong>Human-translation by Doug and Emmanuel</strong></p>
</div>
<div>
<blockquote>
<div>
<p>Sometimes things just didn’t work out right; no matter how har she wished for it, the dice simply wouldn’t come up her way. But Sagan always took her failures as a playwright much as she took her gambling losses, acknowledging the arbitrary whims of the house and of divine fate. After all, everyone has to lose now and then, so that the next day’s victory will taste all the sweeter. And if you never saw her win back a whole night’s losses, often in well under an hour, you just can’t have any idea of the glee she took in laughing in the face of destiny.</p>
</div>
</blockquote>
</div>
<div>
<p>Then here are the translations over the years (the first two coming from the book itself):</p>
</div>
<div>
<p><strong>Google Translate, 2004</strong></p>
</div>
<div>
<blockquote>
<div>
<p>Sometimes, success was not with go. One thinks of it in vain very extremely, the good number does not leave inevitable. Sagan took the failures of dramatic author like in the reverses of casino, with respect for the whims of the bank and the sky. It is necessary well to lose a little, for better enjoying gains it following day. Who did not see it “recovering” in a few fifteen minutes the losses of a whole night cannot include/understand as they is merry of narguer the fate.</p>
</div>
</blockquote>
</div>
<div>
<p><em>Verdict</em>: Terrible.</p>
</div>
<div>
<p><strong>Google Translate, 2009</strong></p>
</div>
<div>
<blockquote>
<div>
<p>Sometimes, success was not there. It was nice to think very hard, the proper number does not necessarily spell. Sagan took the failures as a dramatist such as backhand casino, with respect to the whims of the Bank and the sky. It must be losig a little, better enjoy the gains overnight. Who did not see “recover” in a few minutes lost a whole night can not understand how happy it is the sort of taunt.</p>
</div>
</blockquote>
</div>
<div>
<p><em>Verdict</em>: Still terrible.</p>
</div>
<div>
<p><strong>Google Translate, 2018</strong></p>
</div>
<div>
<blockquote>
<div>
<p>Sometimes the success was not there. We can think about it very well, the good number does not necessarily come out. Sagan took dramatic draftsman’s chess like the casino setbacks, with respect for the whims of the bank and the sky. It is necessary to lose a little, to better savor the gain of tomorrow. Whoever has not seen her “recover” in a few quarters of an hour the losses of a whole night can not understand how happy it is to taunt the spell.</p>
</div>
</blockquote>
</div>
<div>
<p><em>Verdict</em>: <em>Still</em> terrible, 14 years later!</p>
</div>
<div>
<p>It’s very interesting to think about how to build systems that could conveivably translate phrases like this “properly”, by using the ideas from the book.</p>
</div>
]]></summary>
</entry>
<entry>
    <title><tt>fugu</tt>, the generalised <tt>relu</tt> activation function</title>
    <link href="https://silky.github.io/posts/2018-06-06-fugu-the-generalised-relu-activation-function.html" />
    <id>https://silky.github.io/posts/2018-06-06-fugu-the-generalised-relu-activation-function.html</id>
    <published>2018-06-06T00:00:00Z</published>
    <updated>2018-06-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on June  6, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>Recall the standard <code>ReLU</code> function from neural networks:</p>
</div>
<div>
<p><br /><span class="math display">$$
\texttt{ReLU}(x) = \max(0, x) = \begin{cases}
    x &amp; x &gt; 0 \\
    0 &amp; \text{otherwise}
    \end{cases}
$$</span><br /></p>
</div>
<div>
<p>All well-and-good. But what if I want to apply a function to the lower-half of this function, instead of setting it to <span class="math inline">0</span>? Infact, what if I want to apply a function to the top-half as well! And while we’re at it, why should the inflexion point be <span class="math inline">0</span> always?</p>
</div>
<div>
<p>So, here’s the <code>fugu</code> function:</p>
</div>
<div>
<p><br /><span class="math display">$$
\texttt{fugu}(x, f, g, p) = \begin{cases}
    g(x) &amp; x &gt; p \\
    f(x) &amp; \text{otherwise}
    \end{cases}
$$</span><br /></p>
</div>
<div>
<p>Then, <span class="math inline"><code>ReLU</code>(<em>x</em>)=<code>fugu</code>(<em>x</em>, 0, id, 0)</span>, if you wish.</p>
</div>
<div>
<p>Here’s the <code>fugu</code> function in Python TensorFlow:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="kw">def</span> fugu (x, f, g<span class="op">=</span><span class="kw">lambda</span> x: x, point<span class="op">=</span><span class="dv">0</span>):
    cond   <span class="op">=</span> tf.less(x, point)
    <span class="cf">return</span> tf.where(cond, f(x), g(x))</code></pre></div>
</div>
<div>
<p>There, <code>tf.nn.relu(x) = fugu(x, tf.zeros_like)</code>.</p>
</div>
<div>
<p>What kinds of cool/useful functions can you build with this?</p>
</div>
<div>
<p>Exercise: Can you use the <code>fugu</code> function to build a kind of “stairway-to-relu” function?</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/stairway-to-relu.png" />
</div>
<div>
</center>
</div>
]]></summary>
</entry>
<entry>
    <title>CPPNs for Procedural Landscape Generation!</title>
    <link href="https://silky.github.io/posts/2018-04-15-cppns-for-procedural-landscape-generation.html" />
    <id>https://silky.github.io/posts/2018-04-15-cppns-for-procedural-landscape-generation.html</id>
    <published>2018-04-15T00:00:00Z</published>
    <updated>2018-04-15T00:00:00Z</updated>
    <summary type="html"><![CDATA[<div class="info">
    Posted on April 15, 2018
    
        by Noon van der Silk
    
</div>

<div>
<center>
</div>
<div>
<i>(Code related to this post: <a href="https://github.com/silky/cppn-3d/">cppn-3d</a>.)</i>
</div>
<div>
</center>
</div>
<div>
<p><br /></p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/funky.png" /> <img src="/images/cppn/funky-3d-sized.png" />
</div>
<div>
</center>
</div>
<div>
<p>So I’ve been obsessed with <a href="https://en.wikipedia.org/wiki/Compositional_pattern-producing_network">CPPN’s</a> ever since I saw this series of blogposts by <a href="https://github.com/hardmaru">Hardmaru</a>:</p>
</div>
<div>
<ul>
<li><div>
<a href="http://blog.otoro.net/2015/06/19/neural-network-generative-art/">Neural Network Generative Art in Javascript</a>
</div></li>
<li><div>
<a href="http://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/">Generating Abstract Patterns with TensorFlow</a>
</div></li>
<li><div>
<a href="http://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/">Generating Large Images from Latent Vectors</a>
</div></li>
<li><div>
<a href="http://blog.otoro.net/2016/06/02/generating-large-images-from-latent-vectors-part-two/">Generating Large Images from Latent Vectors - Part Two</a>
</div></li>
<li><div>
<a href="http://blog.otoro.net/2016/04/06/the-frog-of-cifar-10/">The Frog of CIFAR 10</a>
</div></li>
</ul>
</div>
<div>
<p>One of the main reasons I loved this idea so much is that almost all machine learning that you see concerns itself with fixed output dimensions; at least for images. The cool thing about the CPPN is that it maps <em>pixel coordinates</em>, along with some configurably latent-vector <span class="math inline">$\vec{z}$</span>, to <em>rgb values</em>:</p>
</div>
<div>
<p><br /><span class="math display">$$
\text{cppn}(x, y, \vec{z}) = (r,g,b)
$$</span><br /></p>
</div>
<div>
<p>This is cool because, there is a value defined for every point! So you can use these things to create arbitrarily-large pictures! Furthermore, for a given <span class="math inline">$\vec{z}$</span> we can make higher-resolution images by evaluating the network over different widths.</p>
</div>
<div>
<p>At Silverpond we’ve put this idea to good use in our upcoming event at <a href="https://mkw.melbourne.vic.gov.au/events/ai-fashion-designer/">Melbourne Knowledge Week</a>.</p>
</div>
<div>
<p>In any case, here I’d like to document my playing-around with the idea of using CPPNs to generate 3d landscapes.</p>
</div>
<div>
<p>I’ve put together some pieces of code here: <a href="https://github.com/silky/cppn-3d">cppn-3d</a>. Thanks to the amazing <a href="mybinder.org">MyBinder</a> you can even <a href="https://mybinder.org/v2/gh/silky/cppn-3d/master?filepath=python%2FGenerate%20Maps.ipynb">run the notebook online, right now,</a> and start generating your own cool images!</p>
</div>
<div>
<p>To use the Python code, say, take a look at the <a href="https://github.com/silky/cppn-3d/blob/master/python/Generate%20Maps.ipynb">notebook</a> and you’ll see something like this (after imports):</p>
</div>
<div>
<pre><code>latent_dim = 9
TAXICAB    = ft.partial(np.linalg.norm, axis=0, ord=1)
EUCLIDEAN  = ft.partial(np.linalg.norm, axis=0, ord=2)
INF        = ft.partial(np.linalg.norm, axis=0, ord=np.inf)

norms = []

c = Config( net_size   = 20
          , num_dense  = 5
          , latent_dim = latent_dim
          , colours    = 3
          , input_size = 1 + 1 + len(norms) + latent_dim
          , norms      = norms
          , activation_function = tf.nn.tanh
          )

size   = 512
width  = size
height = size

m = build_model(c)
z = np.random.normal(0, 1, size=c.latent_dim)

sess.run(tf.global_variables_initializer())

yss = forward(sess, c, m, z, width, height)
ys  = stitch_together(yss)</code></pre>
</div>
<div>
<p>The magic here is that we can get quite different pictures by mucking around with the params: <code>net_size</code>, <code>num_dense</code>, <code>norms</code>, <code>activation_function</code> and basically just about anything!</p>
</div>
<div>
<p>The very simplistic idea I had was that we can generate images with nice smooth colours, then just map those colours to heights, and that’s the end of it! I did this in <a href="https://threejs.org/">three.js</a> and <a href="https://js.tensorflow.org/">TensorFlow.js</a> at first, with some terrible code:</p>
</div>
<div>
<center>
</div>
<div>
<img width="512" src="/images/cppn/ex1.png" />
</div>
<div>
</center>
</div>
<div>
<p>It worked! You can also <a href="https://silky.github.io/cppn-3d/javascript/index.html">play with this live</a> if you wish; it does a kind of cool animation, albeit kinda slowly.</p>
</div>
<div>
<p>Of course, what I really wanted was to get a feel for how “walkable” or “playable” the resulting map would be. So I found my way to Unity3D, and half-wrote half-googled a tiny script to load in the image as a height map:</p>
</div>
<div>
<div class="sourceCode"><pre class="sourceCode c#"><code class="sourceCode cs"><span class="kw">using</span> System.<span class="fu">IO</span>;
<span class="kw">using</span> UnityEngine;

<span class="kw">public</span> <span class="kw">class</span> TerrainHeight : MonoBehaviour {
    <span class="kw">public</span> <span class="dt">int</span> height  = <span class="dv">400</span>;
    <span class="kw">public</span> <span class="dt">int</span> width   = <span class="dv">400</span>;
    <span class="kw">public</span> <span class="dt">int</span> depth   = <span class="dv">200</span>;
    <span class="kw">public</span> <span class="dt">string</span> cppnImage = <span class="st">&quot;/home/noon/dev/cppn-3d/python/multi-2.png&quot;</span>;


	<span class="dt">void</span> <span class="fu">Start</span> () {
        Terrain terrain     = GetComponent&lt;Terrain&gt;();
        terrain.<span class="fu">terrainData</span> = <span class="fu">GenerateTerrain</span>(terrain.<span class="fu">terrainData</span>);
	}
	

	TerrainData <span class="fu">GenerateTerrain</span> (TerrainData data) {
        data.<span class="fu">size</span> = <span class="kw">new</span> <span class="fu">Vector3</span>(width, depth, height);
		data.<span class="fu">SetHeights</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="fu">GenerateHeights</span>());
        <span class="kw">return</span> data;
	}


    <span class="kw">public</span> <span class="kw">static</span> Texture2D <span class="fu">LoadPng</span> (<span class="dt">string</span> filePath) {
        <span class="dt">byte</span>[] data       = File.<span class="fu">ReadAllBytes</span>(filePath);
        Texture2D texture = <span class="kw">new</span> <span class="fu">Texture2D</span>(<span class="dv">2</span>, <span class="dv">2</span>);
        texture.<span class="fu">LoadImage</span>(data);
        <span class="kw">return</span> texture;
    }


    <span class="dt">float</span>[,] <span class="fu">GenerateHeights</span> () {
        <span class="dt">float</span>[,] heights = <span class="kw">new</span> <span class="dt">float</span>[width, height];
        Texture2D image = <span class="fu">LoadPng</span>(cppnImage);
        <span class="kw">for</span> (<span class="dt">int</span> x = <span class="dv">0</span>; x &lt; width; x++) {
            <span class="kw">for</span> (<span class="dt">int</span> y = <span class="dv">0</span>; y &lt; height; y++) {
                Color colour = image.<span class="fu">GetPixel</span>(x, y);

                <span class="dt">float</span> height = colour.<span class="fu">r</span>
                             + colour.<span class="fu">g</span>
                             + colour.<span class="fu">b</span>;

                heights[x, y] = height / <span class="dv">3</span>;
            }
        }

        <span class="kw">return</span> heights;
    }
}</code></pre></div>
</div>
<div>
<p>In Unity3D, you attach this script to a terrain, then when you run it, it will set that piece of terrain to have the given heights you want!</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/viewpoint.png" />
</div>
<div>
</center>
</div>
<div>
<p>Looks alright! Obviously my general Unity skills need work, but at least it looks something like a landscape! Here’s a few more of the top view generate by a bunch of similarly produced images:</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/a.png" /> <img src="/images/cppn/b.png" /> <img src="/images/cppn/c.png" /> <img src="/images/cppn/d.png" /> <img src="/images/cppn/e.png" /> <img src="/images/cppn/f.png" /> <img src="/images/cppn/g.png" />
</div>
<div>
</center>
</div>
<div>
<p>The images that generated these (not in order) are in the <a href="https://github.com/silky/cppn-3d/tree/master/python/maps">maps</a> folder:</p>
</div>
<div>
<center>
</div>
<div>
<img width="250" src="/images/cppn/night-pond.png" /> <img width="250" src="/images/cppn/egg.png" /> <img width="250" src="/images/cppn/purple-rain.png" /> <img width="250" src="/images/cppn/raddish.png" /> <img width="250" src="/images/cppn/rose.png" /> <img width="250" src="/images/cppn/sharp-purple.png" /> <img width="250" src="/images/cppn/smooth-sand.png" />
</div>
<div>
</center>
</div>
<div>
<p>Anyway, I hope someone finds this useful! I hope I can play with this idea a bit more! I think there’s a lot of juice to squeeze here, in terms of using CPPNs to generate different levels of detail; to add much more detail to the Unity terrain by making decisions based on height (such as where water goes, where snow starts, etc). Furthermore, it would also be neat to auto-generate town locations, and just about everything! Then of course there’s all the details of the CPPN itself to play with; the layer structure, adding more variables, using different norms to highlight different regions of the resulting image; the mind boggles at the options!</p>
</div>
<div>
<p>I hope this demonstrates how fun CPPNs can be!</p>
</div>
<div>
<h3 id="aside">Aside</h3>
</div>
<div>
<p>As an aside, early in the day I was experimenting with producing large tiled images.</p>
</div>
<div>
<p>The basic idea is conveyed here:</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/next-tile.png" />
</div>
<div>
</center>
</div>
<div>
<p>On the left I have a particular image that I’ve generated. I want to continue this image downwards by one tile. On the right is the same image with the next tile.</p>
</div>
<div>
<p>This idea was due to <a href="https://www.linkedin.com/in/galacamacho/">Gala</a> (who works for <a href="https://www.neighbourlytics.com/">Neighbourlytics</a>): basically, given that we have the optimisation machinery at hand, why not just attempt to find a new image, from the network, whose border matches at the point we’re interested in.</p>
</div>
<div>
<p>Initially, my idea was that I could do this by optimising over the z vector <span class="math inline">$\vec{z}$</span> only; i.e. leave all the other parameters of the network alone. This turned out not to work at all. I’m actually not quite sure why, because my experience with CPPNs is that if <span class="math inline">$\vec{z}$</span> is large, then you can get a whole bunch of variation by modifying it. In any case, I tried it, and while it did manage to make <em>some</em> progress, it was never really particularly good.</p>
</div>
<div>
<p>When that approach didn’t work, I used the one that generated the tile connections from above: I just optimised with respect to the entire CPPN network.</p>
</div>
<div>
<p>There were a few problems with this approach, unfortunately:</p>
</div>
<div>
<ol style="list-style-type: decimal">
<li><div>
<p>The tiles it generated were less “interesting”: In the image above, the one of the left is made of 3 tiles. The top one is the starting one; note it’s complexity. The following two tiles are very low in interesting-ness, but the final one is actually not bad. This perhaps makes sense, as when the optimiser only has to match one colour, it can allow itself some richness in the other region.</p>
</div></li>
<li><div>
<p>It didn’t work when I tried to match up <em>two</em> boundaries:</p>
</div></li>
</ol>
</div>
<div>
<center>
</div>
<div>
<img width="250" src="/images/cppn/multi-1.png" /> <img width="250" src="/images/cppn/multi-2.png" /> <img width="250" src="/images/cppn/multi-3.png" /> <img width="250" src="/images/cppn/multi-4.png" /> <img width="250" src="/images/cppn/multi-6.png" /> <img width="250" src="/images/cppn/multi-7.png" />
</div>
<div>
</center>
</div>
<div>
<p>In all these pictures, the bottom-right tile is very out of sync with it’s two neighbours. This could definitely be fixed “in post”, by simplying blending it, but it’s still slightly unsatisfying that I couldn’t solve this within the CPPN framework. One original idea I had was to solve it by using (something-like) the interpolation process you see in the <a href="https://silky.github.io/cppn-3d/javascript/index.html">live JS example</a>. Namely, we can pick two vectors <span class="math inline">$\vec{z_1}$</span> and <span class="math inline">$\vec{z_2}$</span> and move smoothly between them. When you watch this animate, you can feel like there should be some smoothing operation that would let us draw out a long line in this fashion. I think the approach would be to take, slice-by-slice, new images from vectors <span class="math inline">$\vec{z_{n+1}}$</span>, and use the slices from them to produce a landscape. This feels slightly odd to me, but perhaps would be nice.</p>
</div>
<div>
<p>In the end, my realisation was that I can produce very large maps simply by increasing the richness in the CPPN: increasing the numbers of dense layers, and “net size” (units in the dense layers), and then just simply making a high-resolution version of the resulting image:</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/rich-big.png" /> <a href="/images/cppn/rich-map.png"><img height="512" src="/images/cppn/rich-map.png" /></a>
</div>
<div>
</center>
</div>
<div>
<p>In many ways I think I’m still a bit unsatisfied by this approach. I think ultimately it would be nice to have a grid-layout map:</p>
</div>
<div>
<center>
</div>
<div>
<img src="/images/cppn/cppn-map-dream.png" />
</div>
<div>
</center>
</div>
<div>
<p>Where each block is controlled by some vector <span class="math inline">$\vec{z_i}$</span>, and those can be modified at will. This would definately be possible just by blending in some standard way between the particular <span class="math inline">$\vec{z_i}$</span>-values, but I do still think there should be a CPPN-based solution. One idea <a href="http://sordina.github.io/">Lyndon</a> had was by directly constructing the image from the grid, and then encoding that back into the CPPN, then decoding it, to get the “closest match” that is still smooth between the borders. I think this might work, but here we don’t have an encoding network.</p>
</div>
<div>
<p>If you have any ideas along these lines, or find any of this useful, then <a href="/about.html">I’d love to hear from you</a>!</p>
</div>
<div>
<h2 id="bonus-content-17-apr-2018">Bonus Content <small>(17-Apr-2018)</small></h2>
</div>
<div>
<p>I found a cool plugin in Unity — <a href="https://assetstore.unity.com/packages/tools/terrain/terrain-toolkit-2017-83490">The Terrain Toolkit</a> — that lets me easily add textures, and I worked out how to add a water plane (you just find it in the standard assets, and drag on the “Prefab”, and resize it), so we can give the maps a more earthly look and feel:</p>
</div>
<div>
<center>
</div>
<div>
<a href="/images/cppn/texture-1.png"><img height="300" src="/images/cppn/texture-1.png" /></a> <a href="/images/cppn/texture-2.png"><img height="300" src="/images/cppn/texture-2.png" /></a> <a href="/images/cppn/texture-3.png"><img height="300" src="/images/cppn/texture-3.png" /></a> <a href="/images/cppn/texture-4.png"><img height="300" src="/images/cppn/texture-4.png" /></a>
</div>
<div>
</center>
</div>
<div>
<p>So cool! (I also updated the code so you can more easily express richer layers in the CPPN, check out the Jupyter Notebook <a href="https://github.com/silky/cppn-3d/blob/master/python/Generate%20Maps.ipynb">Generate Maps</a> for more deets.)</p>
</div>
]]></summary>
</entry>

</feed>
