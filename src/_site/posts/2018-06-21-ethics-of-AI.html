<?xml version="1.0" encoding="UTF-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <title>Noon van der Silk - The Ethics of AI - A Scenario-Based Approach</title>
        <link rel="stylesheet" type="text/css" href="../css/default.css" />
        <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        </head>
    <body>
        <div id="header">
            <div id="logo">
                <h1><a href="../">Noon van der Silk</a></h1>
            </div>
            <div id="navigation">
                <a href="../about.html">About</a>
                <a href="../archive.html">Archive</a>
                <a href="../links.html">Links</a>
                <small><a href="../atom.xml">Atom Feed</a></small>
            </div>
        </div>

        <div id="content">
            <h2>The Ethics of AI - A Scenario-Based Approach</h2>

            <div class="info">
    Posted on June 21, 2018
    
        by Noon van der Silk
    
</div>

<div>
<p>There’s lots of talk about the Ethics of AI at the moment. As with any research, there’s too much for any one person to read. Here’s a bunch of papers that I’ve collected haphazardly in the early part of this year:</p>
</div>
<div>
<ul>
<li><div>
<a href="https://scirate.com/arxiv/1711.03846">“Dave…I can assure you…that it’s going to be all right…” – A definition, case for, and survey of algorithmic assurances in human-autonomy trust relationships</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1709.06692">A Voting-Based System for Ethical Decision Making</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1511.06578">Actually, It’s About Ethics in Computational Social Science: A Multi-party Risk-Benefit Framework for Online Community Research</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07373">Attentive Explanations: Justifying Decisions and Pointing to the Evidence (Extended Abstract)</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1502.05838">Automated Reasoning for Robot Ethics</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1702.00137">Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.06881">Children and the Data Cycle: Rights and Ethics in a Big Data World</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1606.06565">Concrete Problems in AI Safety</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07076">Does mitigating ML’s impact disparity require treatment disparity?</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1706.03021">Ethical Artificial Intelligence - An Open Question</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1701.07769">Ethical Considerations in Artificial Intelligence Courses</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1707.05259">Ethics of autonomous information systems towards an artificial thinking</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1504.05603">Formalizing Preference Utilitarianism in Physical World Models</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1703.06354">Goal Conflict in Designing an Autonomous Artificial System</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1610.03229">In The Wild Residual Data Research and Privacy</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1709.05929">Institutionally Distributed Deep Learning Networks</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.05791">Maintaining The Humanity of Our Models</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1607.08289">Mammalian Value Systems</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1710.06882">Mapping for accessibility: A case study of ethics in data science for social good</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.07111">Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.06664">Predict Responsibly: Increasing Fairness by Learning To Defer</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1609.03266">Recovering the History of Informed Consent for Data Science and Internet Industry Research Ethics</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1706.02513">Responsible Autonomy</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1701.02388">Stoic Ethics for Artificial Agents</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1606.02583">The Dark Side of Ethical Robots</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.00561">This robot stinks! Differences between perceived mistreatment of robot and computer partners</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1703.04741">Towards Moral Autonomous Systems</a>
</div></li>
<li><div>
<a href="https://scirate.com/arxiv/1711.05905">Using experimental game theory to transit human values to ethical AI</a>
</div></li>
</ul>
</div>
<div>
<p>One thing I wanted to think about is, speaking as someone working in this field and interested in making changes in my day-to-day life, what kind of tools or ideas would be useful for me? What should I do?</p>
</div>
<div>
<p>Alongside this thought, another thought I had is that I don’t really like big lists of rules. Here’s a few:</p>
</div>
<div>
<ul>
<li><div>
<a href="https://futureoflife.org/ai-principles/">Future of Life</a> (June 2018, relevant items)
</div>
<div>
<ul>
<li><div>
5 - Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.
</div></li>
<li><div>
6 - Safety: AI systems should be safe and secure throughout their operational lifetime, and verifably so where applicable and feasible
</div></li>
<li><div>
7 - Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.
</div></li>
<li><div>
8 - Judical Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.
</div></li>
<li><div>
9 - Responsibility: Designers and building of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.
</div></li>
<li><div>
10 - Value Alignment: Highly autonomous AI systems should be designed so that their goals and behviours
</div></li>
<li><div>
11 - Human Values: AI Systems should be designed and operated so as to be compatible with ideals of human dignift, rights, freedoms, and cultural diversity.
</div></li>
<li><div>
12 - Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.
</div></li>
<li><div>
13 - Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.
</div></li>
<li><div>
14 - Shared Benefit: AI technologies should benefit and empower as many people as possible.
</div></li>
<li><div>
15 - Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.
</div></li>
<li><div>
16 - Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human chose objectives.
</div></li>
<li><div>
17 - Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather an subvert, the social and civic processes on which the health of society depends.
</div></li>
<li><div>
18 - AI Arms Race: An arms race in lethal autonomous weapons should be avoided.
</div></li>
</ul>
</div></li>
<li><div>
<a href="https://www.aiforhumanity.fr/en/">AI For Humanity</a> (June 2018)
</div>
<div>
<ul>
<li><div>
01 - Develop an aggressive data policy
</div></li>
<li><div>
02 - Targeting four strategic sectors
</div></li>
<li><div>
03 - Boosting the potential of French research
</div></li>
<li><div>
04 - Planning for the impact of AI on labour
</div></li>
<li><div>
05 - Making AI more environmentally friendly
</div></li>
<li><div>
06 - Opening up the black boxes of AI
</div></li>
<li><div>
07 - Ensuring that AI supports inclusivity and diversity
</div></li>
</ul>
</div></li>
<li><div>
<a href="http://humansforai.com/">Humans for AI</a> (June 2018)
</div>
<div>
<ul>
<li><div>
Broaden the pipeline of minorities currently in tech careers, seeking to move to careers in AI by being the go to destination for all things AI because we believe that diversity of thought and opinion ultimately builds better products.
</div></li>
<li><div>
Open and inclusive community of people interested in AI by facilitating interactions with experts, practitioners and thought leaders in the field.
</div></li>
<li><div>
Leverage AI to release a set of free products built by this community to further our mission of bringing diversity to AI.
</div></li>
<li><div>
Demystify AI by providing a basic understanding of the concepts, thinking and events in AI for novices and non-technical people interested in how AI will impact their lives and their jobs.
</div></li>
</ul>
</div></li>
<li><div>
<a href="https://arxiv.org/pdf/1606.06565.pdf">Concrete Problems in AI Safety</a> (2016)
</div>
<div>
<ul>
<li><div>
Avoid Negative Side Effects
</div></li>
<li><div>
Avoid Reward Hacking
</div></li>
<li><div>
Scalable Oversight
</div></li>
<li><div>
Safe Exploration
</div></li>
<li><div>
Robustness to Distributional Shift
</div></li>
</ul>
</div></li>
</ul>
</div>
<div>
<p>I have a few problems with these rules:</p>
</div>
<div>
<ul>
<li><div>
It’s easy to imagine situations in which they are counter-productive,
</div></li>
<li><div>
I don’t feel a lot of ownership of them, as I wasn’t involved in their construction,
</div></li>
<li><div>
No-one is enforcing them on me,
</div></li>
<li><div>
They’re often highly impractical or contain colloquial/regional/policital concerns (“Boost French Research …”),
</div></li>
<li><div>
They’re also very overwhelming and demanding,
</div></li>
<li><div>
Even if I <em>say</em> I’m doing these things, how does any non-technical person know? How can I prove it?
</div></li>
</ul>
</div>
<div>
<p>The positive aspects of them are:</p>
</div>
<div>
<ul>
<li><div>
It’s sometimes easy to think about how to apply them to day-to-day work,
</div></li>
<li><div>
They help me think of things that I might not care about day-to-day (i.e. the environmental concerns?),
</div></li>
<li><div>
It might help to lobby governments/organisations to get funding to make progress on certain aspects?
</div></li>
<li><div>
It provides a framework that might be useful for discussing with colleagues/other people
</div></li>
</ul>
</div>
<div>
<p>So, how to make progress here? Would it be useful to establish yet another set of rules, based on and maybe including all existing ones, and then force companies in my local area to obey them? I don’t know. But one thing that I’m starting to think is useful, having been heavily inspired by <a href="https://www.amazon.com/Surfaces-Essences-Analogy-Fuel-Thinking/dp/0465018475/">Surfaces and Essences</a>, is to have a large resource of scenarios that allow any person to explore different ways of resolving them. The scenarios will allow one to draw their own analogies to their current/future/imagined situations, and could form a useful thinking tool.</p>
</div>
<div>
<p>Specifically, rules are produced by thinking about a bunch of scenarios and abstracting over them:</p>
</div>
<div>
<center>
</div>
<div>
<img src="../images/ethics-rules-from-scenarios.png" />
</div>
<div>
</center>
</div>
<div>
<p>So why let’s try just looking at the scenarios themselves, and allowing people to come up with their own rules. In this way, it’ll be more clear when the rules should apply, and it should be more lear how to adjust and add scenarios so-as to continually improve how we handle new situations in life.</p>
</div>
<div>
<h1 id="scenarios">Scenarios</h1>
</div>

        </div>
        <div id="footer">
            <small><a href="http://jaspervdj.be/hakyll">Hakyll</a> was involved here (<a href="https://github.com/silky/silky.github.com">source</a>).
                I have another <a href="https://sites.google.com/site/noonsilk">website</a>. ن
            </small> 
        </div>
        <div id="image_footer"> &nbsp; </div>
    </body>
</html>
